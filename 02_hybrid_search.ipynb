{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 2: Hybrid Search (Dense + Sparse) with FastEmbed\n",
    "\n",
    "## ğŸ¯ Objectives\n",
    "\n",
    "In this notebook, you'll learn:\n",
    "- Why hybrid search outperforms dense-only on real text\n",
    "- How to encode both dense and sparse vectors\n",
    "- Setting up collections with multiple named vectors\n",
    "- Implementing hybrid scoring and fusion strategies\n",
    "- Comparing search quality across different approaches\n",
    "- Understanding when sparse vectors help with rare terms\n",
    "\n",
    "## ğŸ“‹ Prerequisites\n",
    "\n",
    "- `fastembed` (dense & sparse embeddings), `scikit-learn` (metrics)\n",
    "- Collection from Notebook 1, or we'll create a new one\n",
    "- Understanding of vector similarity from Notebook 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Dict, List, Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "from utils import (\n",
    "    get_qdrant_client, ensure_collection, create_sample_dataset,\n",
    "    upsert_points_batch, search_dense, search_hybrid_fusion,\n",
    "    print_search_results, calculate_redundancy, print_system_info\n",
    ")\n",
    "\n",
    "from qdrant_client.models import VectorParams, Distance, Filter, FieldCondition, MatchValue\n",
    "\n",
    "print_system_info()\n",
    "print(\"\\nğŸ”§ Checking FastEmbed availability...\")\n",
    "\n",
    "try:\n",
    "    import fastembed\n",
    "    print(f\"âœ… FastEmbed version: {fastembed.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"âš ï¸ FastEmbed not found. Run: pip install fastembed\")\n",
    "\n",
    "try:\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "    print(\"âœ… Scikit-learn available\")\n",
    "except ImportError:\n",
    "    print(\"âš ï¸ Scikit-learn not found. Run: pip install scikit-learn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“¦ Install Dependencies (if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment if running in a fresh environment\n",
    "# !pip install fastembed scikit-learn matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âš™ï¸ Configuration & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "COLLECTION_NAME = \"workshop_hybrid\"\n",
    "DENSE_SIZE = 384  # Size for dense embeddings\n",
    "\n",
    "# Connect to Qdrant\n",
    "client = get_qdrant_client()\n",
    "\n",
    "qdrant_url = os.getenv(\"QDRANT_URL\", \"http://localhost:6333\")\n",
    "print(f\"ğŸ”— Connected to: {qdrant_url}\")\n",
    "print(f\"ğŸ“ Collection: {COLLECTION_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š Enhanced Dataset\n",
    "\n",
    "Let's create a richer dataset with some multilingual content and domain-specific terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_enhanced_dataset(size: int = 200, seed: int = 42) -> pd.DataFrame:\n",
    "    \"\"\"Create an enhanced dataset with technical terms and multilingual content\"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Base dataset\n",
    "    df = create_sample_dataset(size - 50, seed)\n",
    "    \n",
    "    # Add technical documents with specific terminology\n",
    "    tech_docs = [\n",
    "        {\"text\": \"Vector database indexing with HNSW algorithm optimization\", \"category\": \"technical\", \"lang\": \"en\"},\n",
    "        {\"text\": \"Elasticsearch vs Qdrant performance benchmarks\", \"category\": \"technical\", \"lang\": \"en\"},\n",
    "        {\"text\": \"Machine learning embeddings cosine similarity search\", \"category\": \"technical\", \"lang\": \"en\"},\n",
    "        {\"text\": \"PostgreSQL pgvector extension installation guide\", \"category\": \"technical\", \"lang\": \"en\"},\n",
    "        {\"text\": \"FAISS index types IVF PQ quantization methods\", \"category\": \"technical\", \"lang\": \"en\"},\n",
    "        {\"text\": \"ConfiguraciÃ³n de bÃºsqueda vectorial en espaÃ±ol\", \"category\": \"technical\", \"lang\": \"es\"},\n",
    "        {\"text\": \"Recherche sÃ©mantique avec des embeddings franÃ§ais\", \"category\": \"technical\", \"lang\": \"fr\"},\n",
    "        {\"text\": \"Vektorsuche und Ã„hnlichkeitsmetriken in deutscher Sprache\", \"category\": \"technical\", \"lang\": \"de\"},\n",
    "    ]\n",
    "    \n",
    "    # Add business documents\n",
    "    business_docs = [\n",
    "        {\"text\": \"Quarterly revenue increased by 15% year-over-year growth\", \"category\": \"business\", \"lang\": \"en\"},\n",
    "        {\"text\": \"Customer acquisition cost CAC lifetime value LTV metrics\", \"category\": \"business\", \"lang\": \"en\"},\n",
    "        {\"text\": \"Enterprise SaaS pricing strategy B2B sales pipeline\", \"category\": \"business\", \"lang\": \"en\"},\n",
    "        {\"text\": \"Market penetration competitive analysis strategic positioning\", \"category\": \"business\", \"lang\": \"en\"},\n",
    "    ]\n",
    "    \n",
    "    # Add scientific documents\n",
    "    science_docs = [\n",
    "        {\"text\": \"Neural network architecture transformer attention mechanisms\", \"category\": \"science\", \"lang\": \"en\"},\n",
    "        {\"text\": \"BERT RoBERTa GPT language model fine-tuning\", \"category\": \"science\", \"lang\": \"en\"},\n",
    "        {\"text\": \"Gradient descent optimization Adam optimizer learning rate\", \"category\": \"science\", \"lang\": \"en\"},\n",
    "        {\"text\": \"Convolutional neural networks CNN image classification\", \"category\": \"science\", \"lang\": \"en\"},\n",
    "    ]\n",
    "    \n",
    "    # Combine all additional documents\n",
    "    additional_docs = tech_docs + business_docs + science_docs\n",
    "    \n",
    "    # Add to DataFrame\n",
    "    for i, doc in enumerate(additional_docs):\n",
    "        new_row = {\n",
    "            \"id\": len(df) + i + 1,\n",
    "            \"text\": doc[\"text\"],\n",
    "            \"category\": doc[\"category\"],\n",
    "            \"lang\": doc[\"lang\"],\n",
    "            \"timestamp\": int(np.random.uniform(1640995200, 1704067200))  # 2022-2024\n",
    "        }\n",
    "        df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Create enhanced dataset\n",
    "df = create_enhanced_dataset(size=200, seed=42)\n",
    "\n",
    "print(f\"ğŸ“Š Enhanced dataset: {len(df)} documents\")\n",
    "print(f\"ğŸ“‚ Categories: {df['category'].value_counts().to_dict()}\")\n",
    "print(f\"ğŸŒ Languages: {df['lang'].value_counts().to_dict()}\")\n",
    "\n",
    "# Show some technical examples\n",
    "print(\"\\nğŸ”¬ Technical document samples:\")\n",
    "tech_samples = df[df['category'] == 'technical']['text'].head(3)\n",
    "for i, text in enumerate(tech_samples, 1):\n",
    "    print(f\"  {i}. {text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ—ï¸ Create Hybrid Collection\n",
    "\n",
    "Set up a collection with both dense and sparse vector slots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define multiple named vectors for hybrid search\n",
    "vector_config = {\n",
    "    \"text_dense\": VectorParams(size=DENSE_SIZE, distance=Distance.COSINE),\n",
    "    \"text_sparse\": VectorParams(size=0, distance=Distance.DOT)  # Sparse vectors use size=0\n",
    "}\n",
    "\n",
    "# Create or recreate collection\n",
    "ensure_collection(\n",
    "    client=client,\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    vector_config=vector_config,\n",
    "    force_recreate=True\n",
    ")\n",
    "\n",
    "# Verify collection setup\n",
    "info = client.get_collection(COLLECTION_NAME)\n",
    "print(f\"\\nâœ… Hybrid collection created:\")\n",
    "print(f\"   Collection: {COLLECTION_NAME}\")\n",
    "print(f\"   Points: {info.points_count}\")\n",
    "\n",
    "# Show vector configurations\n",
    "if hasattr(info.config.params, 'vectors') and isinstance(info.config.params.vectors, dict):\n",
    "    print(f\"   Vector configs:\")\n",
    "    for name, config in info.config.params.vectors.items():\n",
    "        print(f\"     {name}: size={config.size}, distance={config.distance}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ Dense Vector Encoding\n",
    "\n",
    "Generate dense embeddings using FastEmbed or a lightweight alternative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_dense_vectors(texts: List[str], model_name: str = \"BAAI/bge-small-en-v1.5\"):\n",
    "    \"\"\"Encode texts to dense vectors using FastEmbed\"\"\"\n",
    "    try:\n",
    "        from fastembed import TextEmbedding\n",
    "        \n",
    "        print(f\"ğŸ”„ Loading dense embedding model: {model_name}\")\n",
    "        embedding_model = TextEmbedding(model_name=model_name)\n",
    "        \n",
    "        print(f\"ğŸ”„ Encoding {len(texts)} texts...\")\n",
    "        embeddings = list(embedding_model.embed(texts))\n",
    "        \n",
    "        # Convert to numpy and normalize\n",
    "        dense_vectors = np.array(embeddings)\n",
    "        dense_vectors = dense_vectors / np.linalg.norm(dense_vectors, axis=1, keepdims=True)\n",
    "        \n",
    "        print(f\"âœ… Dense encoding complete: {dense_vectors.shape}\")\n",
    "        return dense_vectors\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ FastEmbed encoding failed: {e}\")\n",
    "        print(\"ğŸ”„ Falling back to random vectors for demo...\")\n",
    "        \n",
    "        # Fallback: random normalized vectors\n",
    "        np.random.seed(42)\n",
    "        vectors = np.random.randn(len(texts), DENSE_SIZE)\n",
    "        return vectors / np.linalg.norm(vectors, axis=1, keepdims=True)\n",
    "\n",
    "# Encode dense vectors\n",
    "texts = df['text'].tolist()\n",
    "dense_vectors = encode_dense_vectors(texts)\n",
    "\n",
    "print(f\"\\nğŸ“ Dense vectors: {dense_vectors.shape}\")\n",
    "print(f\"ğŸ“ Sample norm: {np.linalg.norm(dense_vectors[0]):.4f} (should be ~1.0)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âš¡ Sparse Vector Encoding\n",
    "\n",
    "Create sparse vectors using either SPLADE/miniCOIL (if available) or BM25-style weighting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sparse_vectors_bm25(texts: List[str], max_features: int = 10000) -> List[Dict[int, float]]:\n",
    "    \"\"\"Create BM25-style sparse vectors using TF-IDF as a proxy\"\"\"\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    from scipy.sparse import csr_matrix\n",
    "    \n",
    "    print(f\"ğŸ”„ Creating BM25-style sparse vectors...\")\n",
    "    \n",
    "    # Use TF-IDF as BM25 approximation\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        max_features=max_features,\n",
    "        lowercase=True,\n",
    "        stop_words='english',\n",
    "        ngram_range=(1, 2),  # Include bigrams\n",
    "        min_df=1,  # Keep rare terms\n",
    "        max_df=0.95  # Remove very common terms\n",
    "    )\n",
    "    \n",
    "    # Fit and transform\n",
    "    tfidf_matrix = vectorizer.fit_transform(texts)\n",
    "    \n",
    "    # Convert to sparse dictionaries\n",
    "    sparse_vectors = []\n",
    "    for i in range(tfidf_matrix.shape[0]):\n",
    "        row = tfidf_matrix.getrow(i)\n",
    "        sparse_dict = {}\n",
    "        \n",
    "        # Get non-zero elements\n",
    "        row_coo = row.tocoo()\n",
    "        for col_idx, value in zip(row_coo.col, row_coo.data):\n",
    "            if value > 0.01:  # Filter very small values\n",
    "                sparse_dict[int(col_idx)] = float(value)\n",
    "        \n",
    "        sparse_vectors.append(sparse_dict)\n",
    "    \n",
    "    print(f\"âœ… Sparse encoding complete: {len(sparse_vectors)} vectors\")\n",
    "    print(f\"ğŸ“Š Avg non-zero elements: {np.mean([len(v) for v in sparse_vectors]):.1f}\")\n",
    "    print(f\"ğŸ”¤ Vocabulary size: {len(vectorizer.vocabulary_)}\")\n",
    "    \n",
    "    return sparse_vectors, vectorizer\n",
    "\n",
    "def encode_sparse_vectors_fastembed(texts: List[str]):\n",
    "    \"\"\"Try to encode sparse vectors using FastEmbed\"\"\"\n",
    "    try:\n",
    "        from fastembed import SparseTextEmbedding\n",
    "        \n",
    "        print(f\"ğŸ”„ Loading sparse embedding model...\")\n",
    "        sparse_model = SparseTextEmbedding(model_name=\"prithivida/Splade_PP_en_v1\")\n",
    "        \n",
    "        print(f\"ğŸ”„ Encoding {len(texts)} texts to sparse vectors...\")\n",
    "        sparse_embeddings = list(sparse_model.embed(texts))\n",
    "        \n",
    "        # Convert to sparse dictionaries\n",
    "        sparse_vectors = []\n",
    "        for embedding in sparse_embeddings:\n",
    "            # FastEmbed sparse embeddings are typically scipy sparse matrices\n",
    "            sparse_dict = {}\n",
    "            if hasattr(embedding, 'tocoo'):\n",
    "                coo = embedding.tocoo()\n",
    "                for idx, value in zip(coo.col, coo.data):\n",
    "                    sparse_dict[int(idx)] = float(value)\n",
    "            sparse_vectors.append(sparse_dict)\n",
    "        \n",
    "        print(f\"âœ… FastEmbed sparse encoding complete: {len(sparse_vectors)} vectors\")\n",
    "        return sparse_vectors, None\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ FastEmbed sparse encoding failed: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# Try FastEmbed sparse first, fall back to BM25-style\n",
    "print(\"ğŸ¯ Option A: Trying FastEmbed sparse vectors...\")\n",
    "sparse_vectors, sparse_model = encode_sparse_vectors_fastembed(texts)\n",
    "\n",
    "if sparse_vectors is None:\n",
    "    print(\"\\nğŸ¯ Option B: Using BM25-style sparse vectors...\")\n",
    "    sparse_vectors, vectorizer = encode_sparse_vectors_bm25(texts)\n",
    "    sparse_model = vectorizer\n",
    "\n",
    "# Show sample sparse vector\n",
    "sample_idx = 0\n",
    "sample_sparse = sparse_vectors[sample_idx]\n",
    "print(f\"\\nğŸ” Sample sparse vector (doc {sample_idx}):\")\n",
    "print(f\"   Text: '{texts[sample_idx][:60]}...'\")\n",
    "print(f\"   Sparse elements: {len(sample_sparse)}\")\n",
    "print(f\"   Top weights: {dict(sorted(sample_sparse.items(), key=lambda x: x[1], reverse=True)[:5])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“¤ Ingest Hybrid Vectors\n",
    "\n",
    "Upload both dense and sparse vectors to our collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client.models import PointStruct, SparseVector\n",
    "from tqdm import tqdm\n",
    "\n",
    "def upsert_hybrid_points(client, collection_name: str, df: pd.DataFrame, \n",
    "                        dense_vectors: np.ndarray, sparse_vectors: List[Dict[int, float]],\n",
    "                        batch_size: int = 50):\n",
    "    \"\"\"Upsert points with both dense and sparse vectors\"\"\"\n",
    "    \n",
    "    points = []\n",
    "    payload_cols = [\"text\", \"category\", \"lang\", \"timestamp\"]\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        # Normalize sparse vector to indices/values\n",
    "        sparse_dict = sparse_vectors[idx]\n",
    "        if len(sparse_dict) > 0:\n",
    "            sorted_items = sorted(sparse_dict.items(), key=lambda kv: int(kv[0]) if isinstance(kv[0], str) else kv[0])\n",
    "            s_indices = [int(k) for k, _ in sorted_items]\n",
    "            s_values = [float(v) for _, v in sorted_items]\n",
    "        else:\n",
    "            s_indices, s_values = [], []\n",
    "        \n",
    "        # Create point with both vector types\n",
    "        point_vectors = {\n",
    "            \"text_dense\": dense_vectors[idx].tolist(),\n",
    "            \"text_sparse\": SparseVector(indices=s_indices, values=s_values)\n",
    "        }\n",
    "        \n",
    "        payload = {col: row[col] for col in payload_cols}\n",
    "        \n",
    "        points.append(PointStruct(\n",
    "            id=int(row[\"id\"]),\n",
    "            vector=point_vectors,\n",
    "            payload=payload\n",
    "        ))\n",
    "    \n",
    "    # Batch upload\n",
    "    print(f\"ğŸ“¤ Uploading {len(points)} hybrid points...\")\n",
    "    for i in tqdm(range(0, len(points), batch_size), desc=\"Uploading\"):\n",
    "        batch = points[i:i + batch_size]\n",
    "        client.upsert(collection_name=collection_name, points=batch)\n",
    "\n",
    "# Upload hybrid vectors\n",
    "upsert_hybrid_points(client, COLLECTION_NAME, df, dense_vectors, sparse_vectors)\n",
    "\n",
    "# Verify upload\n",
    "info = client.get_collection(COLLECTION_NAME)\n",
    "print(f\"\\nâœ… Upload complete: {info.points_count} points in collection\")\n",
    "\n",
    "# Verify hybrid structure by retrieving a sample point\n",
    "sample_point = client.retrieve(COLLECTION_NAME, ids=[1], with_vectors=True)[0]\n",
    "print(f\"\\nğŸ” Sample point structure:\")\n",
    "print(f\"   ID: {sample_point.id}\")\n",
    "print(f\"   Vectors: {list(sample_point.vector.keys()) if sample_point.vector else 'None'}\")\n",
    "if sample_point.vector:\n",
    "    for vec_name, vec_data in sample_point.vector.items():\n",
    "        if isinstance(vec_data, list):\n",
    "            print(f\"     {vec_name}: dense vector, length {len(vec_data)}\")\n",
    "        elif hasattr(vec_data, 'indices') and hasattr(vec_data, 'values'):\n",
    "            print(f\"     {vec_name}: sparse vector, {len(vec_data.indices)} non-zero elements\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ” Dense vs Sparse Search Comparison\n",
    "\n",
    "Let's compare how dense and sparse searches perform on different types of queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test_queries(df: pd.DataFrame, sparse_model) -> List[Dict]:\n",
    "    \"\"\"Create test queries of different types\"\"\"\n",
    "    queries = []\n",
    "    \n",
    "    # Conceptual queries (should favor dense)\n",
    "    queries.extend([\n",
    "        {\"text\": \"machine learning artificial intelligence\", \"type\": \"conceptual\", \"expected_favor\": \"dense\"},\n",
    "        {\"text\": \"customer service help support\", \"type\": \"conceptual\", \"expected_favor\": \"dense\"},\n",
    "        {\"text\": \"database storage optimization performance\", \"type\": \"conceptual\", \"expected_favor\": \"dense\"},\n",
    "    ])\n",
    "    \n",
    "    # Keyword/exact term queries (should favor sparse)\n",
    "    queries.extend([\n",
    "        {\"text\": \"HNSW algorithm\", \"type\": \"keyword\", \"expected_favor\": \"sparse\"},\n",
    "        {\"text\": \"FastEmbed embedding\", \"type\": \"keyword\", \"expected_favor\": \"sparse\"},\n",
    "        {\"text\": \"PostgreSQL pgvector\", \"type\": \"keyword\", \"expected_favor\": \"sparse\"},\n",
    "    ])\n",
    "    \n",
    "    # Mixed queries (should favor hybrid)\n",
    "    queries.extend([\n",
    "        {\"text\": \"vector search optimization techniques\", \"type\": \"mixed\", \"expected_favor\": \"hybrid\"},\n",
    "        {\"text\": \"customer acquisition business metrics\", \"type\": \"mixed\", \"expected_favor\": \"hybrid\"},\n",
    "        {\"text\": \"neural network training optimization\", \"type\": \"mixed\", \"expected_favor\": \"hybrid\"},\n",
    "    ])\n",
    "    \n",
    "    # Encode queries\n",
    "    query_texts = [q[\"text\"] for q in queries]\n",
    "    \n",
    "    # Dense encoding\n",
    "    query_dense = encode_dense_vectors(query_texts)\n",
    "    \n",
    "    # Sparse encoding\n",
    "    if hasattr(sparse_model, 'transform'):  # BM25-style\n",
    "        query_sparse_matrix = sparse_model.transform(query_texts)\n",
    "        query_sparse = []\n",
    "        for i in range(query_sparse_matrix.shape[0]):\n",
    "            row = query_sparse_matrix.getrow(i).tocoo()\n",
    "            sparse_dict = {int(col): float(val) for col, val in zip(row.col, row.data) if val > 0.01}\n",
    "            query_sparse.append(sparse_dict)\n",
    "    else:\n",
    "        # For FastEmbed or fallback\n",
    "        query_sparse = [{i: 1.0 for i, word in enumerate(q[\"text\"].split()[:5])} for q in queries]\n",
    "    \n",
    "    # Add vectors to queries\n",
    "    for i, query in enumerate(queries):\n",
    "        query[\"dense_vector\"] = query_dense[i]\n",
    "        query[\"sparse_vector\"] = query_sparse[i]\n",
    "    \n",
    "    return queries\n",
    "\n",
    "# Create test queries\n",
    "test_queries = create_test_queries(df, sparse_model)\n",
    "print(f\"ğŸ¯ Created {len(test_queries)} test queries:\")\n",
    "for q in test_queries:\n",
    "    print(f\"   {q['type']:>10}: '{q['text']}' (expects {q['expected_favor']} to work best)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âš–ï¸ Run Comparative Search Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_search_comparison(queries: List[Dict], top_k: int = 5):\n",
    "    \"\"\"Compare dense, sparse, and hybrid search results\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for query in queries:\n",
    "        print(f\"\\nğŸ” Query: '{query['text']}' ({query['type']})\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Dense search (named vector handled inside util)\n",
    "        dense_results = search_dense(\n",
    "            client=client,\n",
    "            collection_name=COLLECTION_NAME,\n",
    "            query_vector=query[\"dense_vector\"],\n",
    "            vector_name=\"text_dense\",\n",
    "            limit=top_k,\n",
    "            with_payload=True\n",
    "        )\n",
    "        \n",
    "        # Sparse search (named vector handled inside util)\n",
    "        sparse_results = search_dense(\n",
    "            client=client,\n",
    "            collection_name=COLLECTION_NAME,\n",
    "            query_vector=query[\"sparse_vector\"],\n",
    "            vector_name=\"text_sparse\",\n",
    "            limit=top_k,\n",
    "            with_payload=True\n",
    "        )\n",
    "        \n",
    "        # Hybrid search with client-side fusion\n",
    "        hybrid_results = search_hybrid_fusion(\n",
    "            client=client,\n",
    "            collection_name=COLLECTION_NAME,\n",
    "            dense_vector=query[\"dense_vector\"],\n",
    "            sparse_vector=query[\"sparse_vector\"],\n",
    "            dense_weight=0.5,\n",
    "            limit=20,\n",
    "            final_limit=top_k\n",
    "        )\n",
    "        \n",
    "        # Display results\n",
    "        print(\"\\nğŸŸ¦ DENSE Results:\")\n",
    "        for i, r in enumerate(dense_results[:3]):\n",
    "            print(f\"  {i+1}. [{r.score:.3f}] {r.payload['text'][:50]}...\")\n",
    "        \n",
    "        print(\"\\nğŸŸ¨ SPARSE Results:\")\n",
    "        for i, r in enumerate(sparse_results[:3]):\n",
    "            print(f\"  {i+1}. [{r.score:.3f}] {r.payload['text'][:50]}...\")\n",
    "        \n",
    "        print(\"\\nğŸŸª HYBRID Results:\")\n",
    "        for i, r in enumerate(hybrid_results[:3]):\n",
    "            print(f\"  {i+1}. [{r.score:.3f}] {r.payload['text'][:50]}...\")\n",
    "        \n",
    "        # Calculate metrics\n",
    "        dense_ids = [r.id for r in dense_results]\n",
    "        sparse_ids = [r.id for r in sparse_results]\n",
    "        hybrid_ids = [r.id for r in hybrid_results]\n",
    "        \n",
    "        # Calculate overlaps\n",
    "        dense_sparse_overlap = len(set(dense_ids) & set(sparse_ids)) / top_k\n",
    "        dense_hybrid_overlap = len(set(dense_ids) & set(hybrid_ids)) / top_k\n",
    "        sparse_hybrid_overlap = len(set(sparse_ids) & set(hybrid_ids)) / top_k\n",
    "        \n",
    "        # Calculate redundancy (if we have vectors)\n",
    "        dense_texts = [r.payload['text'] for r in dense_results]\n",
    "        sparse_texts = [r.payload['text'] for r in sparse_results]\n",
    "        hybrid_texts = [r.payload['text'] for r in hybrid_results]\n",
    "        \n",
    "        dense_redundancy = calculate_redundancy(dense_texts)\n",
    "        sparse_redundancy = calculate_redundancy(sparse_texts)\n",
    "        hybrid_redundancy = calculate_redundancy(hybrid_texts)\n",
    "        \n",
    "        result_summary = {\n",
    "            \"query\": query[\"text\"],\n",
    "            \"type\": query[\"type\"],\n",
    "            \"expected_best\": query[\"expected_favor\"],\n",
    "            \"dense_sparse_overlap\": dense_sparse_overlap,\n",
    "            \"dense_hybrid_overlap\": dense_hybrid_overlap,\n",
    "            \"sparse_hybrid_overlap\": sparse_hybrid_overlap,\n",
    "            \"dense_redundancy\": dense_redundancy,\n",
    "            \"sparse_redundancy\": sparse_redundancy,\n",
    "            \"hybrid_redundancy\": hybrid_redundancy,\n",
    "            \"dense_top_score\": dense_results[0].score if dense_results else 0,\n",
    "            \"sparse_top_score\": sparse_results[0].score if sparse_results else 0,\n",
    "            \"hybrid_top_score\": hybrid_results[0].score if hybrid_results else 0,\n",
    "        }\n",
    "        \n",
    "        results.append(result_summary)\n",
    "        \n",
    "        print(f\"\\nğŸ“Š Metrics:\")\n",
    "        print(f\"   Denseâ†”Sparse overlap: {dense_sparse_overlap:.2f}\")\n",
    "        print(f\"   Redundancy - Dense: {dense_redundancy:.3f}, Sparse: {sparse_redundancy:.3f}, Hybrid: {hybrid_redundancy:.3f}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run comparison\n",
    "comparison_results = run_search_comparison(test_queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ˆ Search Quality Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary DataFrame\n",
    "results_df = pd.DataFrame(comparison_results)\n",
    "\n",
    "print(\"ğŸ“Š Search Comparison Summary\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Group by query type\n",
    "type_summary = results_df.groupby('type').agg({\n",
    "    'dense_sparse_overlap': 'mean',\n",
    "    'dense_redundancy': 'mean',\n",
    "    'sparse_redundancy': 'mean', \n",
    "    'hybrid_redundancy': 'mean',\n",
    "    'dense_top_score': 'mean',\n",
    "    'sparse_top_score': 'mean',\n",
    "    'hybrid_top_score': 'mean'\n",
    "}).round(3)\n",
    "\n",
    "print(\"\\nğŸ“‹ By Query Type:\")\n",
    "print(type_summary)\n",
    "\n",
    "# Overall statistics\n",
    "print(\"\\nğŸ¯ Key Insights:\")\n",
    "avg_overlap = results_df['dense_sparse_overlap'].mean()\n",
    "print(f\"   Average Denseâ†”Sparse overlap: {avg_overlap:.2f} ({avg_overlap*100:.0f}% of results)\")\n",
    "\n",
    "# Redundancy comparison\n",
    "avg_dense_redundancy = results_df['dense_redundancy'].mean()\n",
    "avg_sparse_redundancy = results_df['sparse_redundancy'].mean()\n",
    "avg_hybrid_redundancy = results_df['hybrid_redundancy'].mean()\n",
    "\n",
    "print(f\"   Average redundancy:\")\n",
    "print(f\"     Dense: {avg_dense_redundancy:.3f}\")\n",
    "print(f\"     Sparse: {avg_sparse_redundancy:.3f}\")\n",
    "print(f\"     Hybrid: {avg_hybrid_redundancy:.3f}\")\n",
    "\n",
    "if avg_hybrid_redundancy < avg_dense_redundancy:\n",
    "    reduction = (avg_dense_redundancy - avg_hybrid_redundancy) / avg_dense_redundancy * 100\n",
    "    print(f\"   ğŸ‰ Hybrid reduces redundancy by {reduction:.1f}% vs dense-only\")\n",
    "\n",
    "# Score comparison\n",
    "print(f\"\\nâ­ Average top-1 scores:\")\n",
    "print(f\"   Dense: {results_df['dense_top_score'].mean():.3f}\")\n",
    "print(f\"   Sparse: {results_df['sparse_top_score'].mean():.3f}\")\n",
    "print(f\"   Hybrid: {results_df['hybrid_top_score'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š Visualization: Search Method Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualization\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(12, 10))\n",
    "fig.suptitle('Hybrid Search Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Redundancy by search method\n",
    "methods = ['Dense', 'Sparse', 'Hybrid']\n",
    "redundancies = [\n",
    "    results_df['dense_redundancy'].mean(),\n",
    "    results_df['sparse_redundancy'].mean(),\n",
    "    results_df['hybrid_redundancy'].mean()\n",
    "]\n",
    "\n",
    "bars1 = ax1.bar(methods, redundancies, color=['#3498db', '#f39c12', '#9b59b6'])\n",
    "ax1.set_ylabel('Average Redundancy')\n",
    "ax1.set_title('Result Redundancy by Method')\n",
    "ax1.set_ylim(0, max(redundancies) * 1.2)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, value in zip(bars1, redundancies):\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "             f'{value:.3f}', ha='center', va='bottom')\n",
    "\n",
    "# 2. Top scores by search method  \n",
    "top_scores = [\n",
    "    results_df['dense_top_score'].mean(),\n",
    "    results_df['sparse_top_score'].mean(),\n",
    "    results_df['hybrid_top_score'].mean()\n",
    "]\n",
    "\n",
    "bars2 = ax2.bar(methods, top_scores, color=['#3498db', '#f39c12', '#9b59b6'])\n",
    "ax2.set_ylabel('Average Top-1 Score')\n",
    "ax2.set_title('Search Relevance by Method')\n",
    "\n",
    "for bar, value in zip(bars2, top_scores):\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "             f'{value:.3f}', ha='center', va='bottom')\n",
    "\n",
    "# 3. Overlap analysis\n",
    "overlap_data = [\n",
    "    results_df['dense_sparse_overlap'].mean(),\n",
    "    results_df['dense_hybrid_overlap'].mean(),\n",
    "    results_df['sparse_hybrid_overlap'].mean()\n",
    "]\n",
    "overlap_labels = ['Denseâ†”Sparse', 'Denseâ†”Hybrid', 'Sparseâ†”Hybrid']\n",
    "\n",
    "bars3 = ax3.bar(overlap_labels, overlap_data, color=['#e74c3c', '#2ecc71', '#e67e22'])\n",
    "ax3.set_ylabel('Average Overlap Ratio')\n",
    "ax3.set_title('Result Set Overlaps')\n",
    "ax3.set_xticklabels(overlap_labels, rotation=15)\n",
    "\n",
    "for bar, value in zip(bars3, overlap_data):\n",
    "    ax3.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "             f'{value:.2f}', ha='center', va='bottom')\n",
    "\n",
    "# 4. Performance by query type\n",
    "query_types = results_df['type'].unique()\n",
    "x_pos = np.arange(len(query_types))\n",
    "width = 0.25\n",
    "\n",
    "dense_by_type = [results_df[results_df['type'] == qt]['dense_top_score'].mean() for qt in query_types]\n",
    "sparse_by_type = [results_df[results_df['type'] == qt]['sparse_top_score'].mean() for qt in query_types]\n",
    "hybrid_by_type = [results_df[results_df['type'] == qt]['hybrid_top_score'].mean() for qt in query_types]\n",
    "\n",
    "ax4.bar(x_pos - width, dense_by_type, width, label='Dense', color='#3498db', alpha=0.8)\n",
    "ax4.bar(x_pos, sparse_by_type, width, label='Sparse', color='#f39c12', alpha=0.8)\n",
    "ax4.bar(x_pos + width, hybrid_by_type, width, label='Hybrid', color='#9b59b6', alpha=0.8)\n",
    "\n",
    "ax4.set_ylabel('Average Top-1 Score')\n",
    "ax4.set_title('Performance by Query Type')\n",
    "ax4.set_xticks(x_pos)\n",
    "ax4.set_xticklabels(query_types)\n",
    "ax4.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nğŸ“ˆ Chart Interpretation:\")\n",
    "print(\"   â€¢ Lower redundancy = more diverse results\")\n",
    "print(\"   â€¢ Higher top-1 score = more relevant top result\")\n",
    "print(\"   â€¢ Lower overlap = methods find different results\")\n",
    "print(\"   â€¢ Query type performance shows method strengths\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ” Explainability: Understanding Sparse Contributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_sparse_results(query_dict: Dict, results: List, sparse_model, top_n: int = 3):\n",
    "    \"\"\"Show which sparse terms contributed most to each result\"\"\"\n",
    "    print(f\"\\nğŸ” Sparse Explainability for: '{query_dict['text']}'\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    query_sparse = query_dict['sparse_vector']\n",
    "    \n",
    "    # Show query terms\n",
    "    if hasattr(sparse_model, 'get_feature_names_out'):\n",
    "        feature_names = sparse_model.get_feature_names_out()\n",
    "        query_terms = []\n",
    "        for token_id, weight in sorted(query_sparse.items(), key=lambda x: x[1], reverse=True)[:5]:\n",
    "            if token_id < len(feature_names):\n",
    "                query_terms.append(f\"{feature_names[token_id]}({weight:.3f})\")\n",
    "        print(f\"ğŸ¯ Query terms: {', '.join(query_terms)}\")\n",
    "    \n",
    "    print(f\"\\nğŸ“‹ Top {top_n} results:\")\n",
    "    for i, result in enumerate(results[:top_n]):\n",
    "        print(f\"\\n{i+1}. [{result.score:.3f}] {result.payload['text'][:70]}...\")\n",
    "        \n",
    "        # Get document sparse vector\n",
    "        doc_point = client.retrieve(\n",
    "            collection_name=COLLECTION_NAME, \n",
    "            ids=[result.id], \n",
    "            with_vectors=[\"text_sparse\"]\n",
    "        )[0]\n",
    "        \n",
    "        if doc_point.vector and \"text_sparse\" in doc_point.vector:\n",
    "            doc_sparse = doc_point.vector[\"text_sparse\"]\n",
    "            \n",
    "            # Find matching terms\n",
    "            matches = []\n",
    "            for token_id in query_sparse.keys():\n",
    "                if str(token_id) in doc_sparse or token_id in doc_sparse:\n",
    "                    key = str(token_id) if str(token_id) in doc_sparse else token_id\n",
    "                    doc_weight = doc_sparse[key]\n",
    "                    query_weight = query_sparse[token_id]\n",
    "                    contribution = query_weight * doc_weight\n",
    "                    \n",
    "                    if hasattr(sparse_model, 'get_feature_names_out') and token_id < len(feature_names):\n",
    "                        term = feature_names[token_id]\n",
    "                        matches.append((term, contribution))\n",
    "                    else:\n",
    "                        matches.append((f\"term_{token_id}\", contribution))\n",
    "            \n",
    "            # Show top matching terms\n",
    "            matches.sort(key=lambda x: x[1], reverse=True)\n",
    "            if matches:\n",
    "                top_matches = matches[:3]\n",
    "                match_strs = [f\"{term}({contrib:.3f})\" for term, contrib in top_matches]\n",
    "                print(f\"   ğŸ¯ Key matches: {', '.join(match_strs)}\")\n",
    "\n",
    "# Explain results for a technical query\n",
    "tech_query = next(q for q in test_queries if q['type'] == 'keyword' and 'HNSW' in q['text'])\n",
    "\n",
    "# Get sparse results for this query\n",
    "tech_sparse_results = search_dense(\n",
    "    client=client,\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    query_vector=tech_query[\"sparse_vector\"],\n",
    "    vector_name=\"text_sparse\",\n",
    "    limit=5,\n",
    "    with_payload=True\n",
    ")\n",
    "\n",
    "explain_sparse_results(tech_query, tech_sparse_results, sparse_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸŒ Multi-Language Search Benefits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_multilingual_search():\n",
    "    \"\"\"Show how hybrid search helps with multilingual content\"\"\"\n",
    "    print(\"ğŸŒ Multi-Language Search Benefits\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Test with a technical term that appears in multiple languages\n",
    "    multilingual_queries = [\n",
    "        {\"text\": \"vector search\", \"expected_langs\": [\"en\", \"es\", \"fr\"]},\n",
    "        {\"text\": \"embedding\", \"expected_langs\": [\"en\", \"fr\"]},\n",
    "        {\"text\": \"optimization\", \"expected_langs\": [\"en\", \"es\", \"de\"]}\n",
    "    ]\n",
    "    \n",
    "    for query_info in multilingual_queries:\n",
    "        query_text = query_info[\"text\"]\n",
    "        print(f\"\\nğŸ” Query: '{query_text}'\")\n",
    "        \n",
    "        # Encode query\n",
    "        query_dense = encode_dense_vectors([query_text])[0]\n",
    "        \n",
    "        if hasattr(sparse_model, 'transform'):\n",
    "            query_sparse_matrix = sparse_model.transform([query_text])\n",
    "            query_sparse_dict = {}\n",
    "            row = query_sparse_matrix.getrow(0).tocoo()\n",
    "            for col, val in zip(row.col, row.data):\n",
    "                if val > 0.01:\n",
    "                    query_sparse_dict[int(col)] = float(val)\n",
    "        else:\n",
    "            query_sparse_dict = {i: 1.0 for i, word in enumerate(query_text.split())}\n",
    "        \n",
    "        # Hybrid search\n",
    "        results = search_hybrid_fusion(\n",
    "            client=client,\n",
    "            collection_name=COLLECTION_NAME,\n",
    "            dense_vector=query_dense,\n",
    "            sparse_vector=query_sparse_dict,\n",
    "            dense_weight=0.6,  # Slightly favor dense for cross-language\n",
    "            limit=20,\n",
    "            final_limit=8\n",
    "        )\n",
    "        \n",
    "        # Analyze language distribution\n",
    "        lang_counts = {}\n",
    "        for result in results:\n",
    "            lang = result.payload.get('lang', 'unknown')\n",
    "            lang_counts[lang] = lang_counts.get(lang, 0) + 1\n",
    "        \n",
    "        print(f\"   ğŸ“Š Language distribution: {lang_counts}\")\n",
    "        \n",
    "        # Show top results by language\n",
    "        shown_langs = set()\n",
    "        for result in results[:6]:\n",
    "            lang = result.payload.get('lang', 'unknown')\n",
    "            if lang not in shown_langs:\n",
    "                print(f\"   ğŸŒ {lang.upper()}: [{result.score:.3f}] {result.payload['text'][:50]}...\")\n",
    "                shown_langs.add(lang)\n",
    "            if len(shown_langs) >= 3:\n",
    "                break\n",
    "\n",
    "# Run multilingual test\n",
    "test_multilingual_search()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ›ï¸ Hybrid Weight Tuning\n",
    "\n",
    "Experiment with different fusion weights to optimize hybrid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_fusion_weights(query_dict: Dict, weights: List[float] = [0.2, 0.5, 0.8]):\n",
    "    \"\"\"Test different dense/sparse fusion weights\"\"\"\n",
    "    print(f\"\\nğŸ›ï¸ Fusion Weight Testing: '{query_dict['text']}'\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    results_by_weight = {}\n",
    "    \n",
    "    for weight in weights:\n",
    "        print(f\"\\nâš–ï¸ Dense weight: {weight} (Sparse weight: {1-weight})\")\n",
    "        \n",
    "        hybrid_results = search_hybrid_fusion(\n",
    "            client=client,\n",
    "            collection_name=COLLECTION_NAME,\n",
    "            dense_vector=query_dict[\"dense_vector\"],\n",
    "            sparse_vector=query_dict[\"sparse_vector\"],\n",
    "            dense_weight=weight,\n",
    "            limit=20,\n",
    "            final_limit=5\n",
    "        )\n",
    "        \n",
    "        results_by_weight[weight] = hybrid_results\n",
    "        \n",
    "        # Show top 3 results\n",
    "        for i, result in enumerate(hybrid_results[:3]):\n",
    "            print(f\"  {i+1}. [{result.score:.3f}] {result.payload['text'][:45]}...\")\n",
    "        \n",
    "        # Calculate diversity metrics\n",
    "        texts = [r.payload['text'] for r in hybrid_results]\n",
    "        redundancy = calculate_redundancy(texts)\n",
    "        \n",
    "        categories = [r.payload['category'] for r in hybrid_results]\n",
    "        category_diversity = len(set(categories)) / len(categories) if categories else 0\n",
    "        \n",
    "        print(f\"     ğŸ“Š Redundancy: {redundancy:.3f}, Category diversity: {category_diversity:.3f}\")\n",
    "    \n",
    "    # Compare result stability across weights\n",
    "    print(f\"\\nğŸ”„ Result Stability Analysis:\")\n",
    "    weight_pairs = [(0.2, 0.5), (0.5, 0.8), (0.2, 0.8)]\n",
    "    \n",
    "    for w1, w2 in weight_pairs:\n",
    "        if w1 in results_by_weight and w2 in results_by_weight:\n",
    "            ids1 = [r.id for r in results_by_weight[w1][:5]]\n",
    "            ids2 = [r.id for r in results_by_weight[w2][:5]]\n",
    "            overlap = len(set(ids1) & set(ids2)) / 5\n",
    "            print(f\"   Weight {w1} â†” {w2} overlap: {overlap:.2f}\")\n",
    "\n",
    "# Test on different query types\n",
    "for query_type in ['conceptual', 'keyword', 'mixed']:\n",
    "    query = next(q for q in test_queries if q['type'] == query_type)\n",
    "    test_fusion_weights(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“‹ Summary & Best Practices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final collection stats\n",
    "final_info = client.get_collection(COLLECTION_NAME)\n",
    "\n",
    "print(\"ğŸ‰ Hybrid Search Summary\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "print(f\"\\nğŸ“š Collection: {COLLECTION_NAME}\")\n",
    "print(f\"   ğŸ“Š Total points: {final_info.points_count}\")\n",
    "print(f\"   ğŸ¯ Vector types: Dense ({DENSE_SIZE}D) + Sparse (variable)\")\n",
    "print(f\"   ğŸŒ Languages: {len(df['lang'].unique())} ({', '.join(df['lang'].unique())})\")\n",
    "print(f\"   ğŸ“‚ Categories: {len(df['category'].unique())} ({', '.join(df['category'].unique())})\")\n",
    "\n",
    "print(f\"\\nğŸ” Search Methods Compared:\")\n",
    "print(\"   âœ… Dense vector search (semantic similarity)\")\n",
    "print(\"   âœ… Sparse vector search (keyword matching)\")\n",
    "print(\"   âœ… Hybrid fusion (client-side score combination)\")\n",
    "\n",
    "# Key insights from our analysis\n",
    "avg_overlap = pd.DataFrame(comparison_results)['dense_sparse_overlap'].mean()\n",
    "redundancy_improvement = (\n",
    "    pd.DataFrame(comparison_results)['dense_redundancy'].mean() - \n",
    "    pd.DataFrame(comparison_results)['hybrid_redundancy'].mean()\n",
    ") / pd.DataFrame(comparison_results)['dense_redundancy'].mean() * 100\n",
    "\n",
    "print(f\"\\nğŸ“Š Key Findings:\")\n",
    "print(f\"   â€¢ Denseâ†”Sparse overlap: {avg_overlap:.1%} (shows complementarity)\")\n",
    "print(f\"   â€¢ Hybrid reduces redundancy by ~{redundancy_improvement:.1f}%\")\n",
    "print(f\"   â€¢ Keyword queries favor sparse vectors\")\n",
    "print(f\"   â€¢ Conceptual queries favor dense vectors\")\n",
    "print(f\"   â€¢ Mixed queries benefit from hybrid fusion\")\n",
    "\n",
    "print(f\"\\nğŸ¯ Best Practices:\")\n",
    "print(\"   ğŸ”¹ Use dense weight 0.5-0.7 for general queries\")\n",
    "print(\"   ğŸ”¹ Increase sparse weight for exact term matching\")\n",
    "print(\"   ğŸ”¹ Increase dense weight for cross-language search\")\n",
    "print(\"   ğŸ”¹ Monitor result diversity vs relevance trade-offs\")\n",
    "print(\"   ğŸ”¹ A/B test fusion weights for your domain\")\n",
    "\n",
    "print(f\"\\nğŸš€ Ready for Notebook 3: MMR Reranking!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ® Stretch Goals (Optional)\n",
    "\n",
    "Explore advanced hybrid search techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ”„ Server-Side Hybrid Search\n",
    "\n",
    "If your Qdrant version supports server-side hybrid search, compare it with client-side fusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is experimental - server-side hybrid search may not be available in all versions\n",
    "def try_server_side_hybrid(query_dict: Dict):\n",
    "    \"\"\"Attempt server-side hybrid search if available\"\"\"\n",
    "    try:\n",
    "        # Note: This is hypothetical API - actual implementation may differ\n",
    "        # from qdrant_client.models import HybridQuery\n",
    "        \n",
    "        print(\"ğŸ”„ Attempting server-side hybrid search...\")\n",
    "        \n",
    "        # This would be the ideal API:\n",
    "        # results = client.search(\n",
    "        #     collection_name=COLLECTION_NAME,\n",
    "        #     query=HybridQuery(\n",
    "        #         dense={\"vector\": query_dict[\"dense_vector\"].tolist(), \"weight\": 0.5},\n",
    "        #         sparse={\"vector\": query_dict[\"sparse_vector\"], \"weight\": 0.5}\n",
    "        #     ),\n",
    "        #     limit=5\n",
    "        # )\n",
    "        \n",
    "        print(\"âš ï¸  Server-side hybrid search not yet available in this Qdrant version\")\n",
    "        print(\"   Using client-side fusion as demonstrated above\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸  Server-side hybrid search not available: {e}\")\n",
    "        print(\"   This feature may be added in future Qdrant versions\")\n",
    "\n",
    "# Try server-side hybrid\n",
    "sample_query = test_queries[0]\n",
    "try_server_side_hybrid(sample_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸšï¸ Dynamic Weight Adjustment\n",
    "\n",
    "Implement query-adaptive fusion weights based on query characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaptive_fusion_weight(query_text: str) -> float:\n",
    "    \"\"\"Dynamically adjust fusion weights based on query characteristics\"\"\"\n",
    "    \n",
    "    # Heuristics for fusion weight adjustment\n",
    "    base_dense_weight = 0.5\n",
    "    \n",
    "    # Technical terms favor sparse\n",
    "    technical_terms = ['algorithm', 'api', 'database', 'vector', 'embedding', \n",
    "                      'hnsw', 'postgresql', 'optimization', 'benchmark']\n",
    "    technical_score = sum(1 for term in technical_terms if term.lower() in query_text.lower())\n",
    "    \n",
    "    # Short queries favor sparse\n",
    "    word_count = len(query_text.split())\n",
    "    \n",
    "    # Quoted terms favor sparse\n",
    "    has_quotes = '\"' in query_text\n",
    "    \n",
    "    # Adjust weight\n",
    "    adjustment = 0\n",
    "    \n",
    "    if technical_score > 0:\n",
    "        adjustment -= 0.1 * technical_score  # Favor sparse\n",
    "    \n",
    "    if word_count <= 3:\n",
    "        adjustment -= 0.15  # Favor sparse for short queries\n",
    "    \n",
    "    if has_quotes:\n",
    "        adjustment -= 0.2  # Strongly favor sparse for exact matches\n",
    "    \n",
    "    if word_count > 6:\n",
    "        adjustment += 0.1  # Favor dense for longer, conceptual queries\n",
    "    \n",
    "    # Apply bounds\n",
    "    final_weight = max(0.1, min(0.9, base_dense_weight + adjustment))\n",
    "    \n",
    "    return final_weight\n",
    "\n",
    "# Test adaptive weights\n",
    "print(\"ğŸ¤– Adaptive Fusion Weight Examples:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "test_queries_adaptive = [\n",
    "    \"HNSW algorithm\",\n",
    "    \"machine learning models for text classification\", \n",
    "    \"\\\"exact phrase search\\\"\",\n",
    "    \"customer service help\",\n",
    "    \"postgresql pgvector setup\"\n",
    "]\n",
    "\n",
    "for query_text in test_queries_adaptive:\n",
    "    weight = adaptive_fusion_weight(query_text)\n",
    "    print(f\"'{query_text}'\")\n",
    "    print(f\"   â†’ Dense weight: {weight:.2f}, Sparse weight: {1-weight:.2f}\")\n",
    "    \n",
    "    # Explain reasoning\n",
    "    if weight < 0.4:\n",
    "        print(\"   ğŸ“ Favors sparse (keyword/technical query)\")\n",
    "    elif weight > 0.6:\n",
    "        print(\"   ğŸ“ Favors dense (conceptual/long query)\")\n",
    "    else:\n",
    "        print(\"   ğŸ“ Balanced fusion\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ§¹ Cleanup (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to clean up the collection\n",
    "# PRESERVE_COLLECTIONS = True  # Set to False to delete\n",
    "\n",
    "# if not PRESERVE_COLLECTIONS:\n",
    "#     try:\n",
    "#         client.delete_collection(COLLECTION_NAME)\n",
    "#         print(f\"ğŸ—‘ï¸ Deleted collection: {COLLECTION_NAME}\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"Note: Could not delete collection: {e}\")\n",
    "# else:\n",
    "#     print(f\"ğŸ’¾ Collection preserved: {COLLECTION_NAME}\")\n",
    "\n",
    "print(f\"\\nâœ¨ Notebook 2 complete! Move on to 03_mmr_reranking.ipynb\")\n",
    "print(f\"\\nğŸ¯ In the next notebook, we'll learn how to rerank these hybrid results\")\n",
    "print(f\"   using Maximal Marginal Relevance to reduce redundancy and improve diversity!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
