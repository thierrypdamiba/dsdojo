{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 4: HNSW Index Health - Churn, Degradation & Healing\n",
    "\n",
    "## üéØ Objectives\n",
    "\n",
    "In this notebook, you'll learn:\n",
    "- How HNSW (Hierarchical Navigable Small World) graphs work\n",
    "- Why heavy updates/deletes can reduce recall quality\n",
    "- How to measure index health and performance degradation\n",
    "- Techniques for \"healing\" or rebuilding degraded indexes\n",
    "- Monitoring strategies for production vector databases\n",
    "- HNSW parameter tuning for optimal performance\n",
    "\n",
    "## üìã Prerequisites\n",
    "\n",
    "- Understanding of vector similarity search\n",
    "- Basic knowledge of approximate nearest neighbor (ANN) algorithms\n",
    "- A collection with several thousand points for meaningful analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils import (\n",
    "    get_qdrant_client, ensure_collection, create_sample_dataset,\n",
    "    upsert_points_batch, search_dense, exact_topk, \n",
    "    calculate_recall_at_k, measure_latency, print_system_info\n",
    ")\n",
    "\n",
    "from qdrant_client.models import VectorParams, Distance, PointStruct, HnswConfigDiff, OptimizersConfigDiff\n",
    "\n",
    "print_system_info()\n",
    "print(\"\\nüîß HNSW Index Health Workshop\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Install Dependencies (if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment if running in a fresh environment\n",
    "# !pip install qdrant-client numpy pandas matplotlib tqdm scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß† HNSW Theory & Background\n",
    "\n",
    "### What is HNSW?\n",
    "\n",
    "HNSW (Hierarchical Navigable Small World) is a graph-based algorithm for approximate nearest neighbor search:\n",
    "\n",
    "- **Graph Structure**: Each vector is a node connected to nearby vectors\n",
    "- **Hierarchical**: Multiple layers with different connection densities\n",
    "- **Navigable**: Search follows graph edges to find nearest neighbors\n",
    "- **Small World**: Short paths between any two nodes\n",
    "\n",
    "### Why Does Index Health Matter?\n",
    "\n",
    "- **Updates/Deletes**: Can create isolated nodes or suboptimal connections\n",
    "- **Recall Degradation**: Poor connections lead to missed relevant results\n",
    "- **Performance Impact**: Longer search paths increase latency\n",
    "- **Production Reliability**: Degraded indexes hurt user experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_hnsw_degradation():\n",
    "    \"\"\"Visual explanation of HNSW degradation\"\"\"\n",
    "    print(\"üèóÔ∏è HNSW Index Health Concepts\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    print(\"\\nüìç Healthy HNSW Index:\")\n",
    "    print(\"   ‚Ä¢ Well-connected graph structure\")\n",
    "    print(\"   ‚Ä¢ Short paths between similar vectors\")\n",
    "    print(\"   ‚Ä¢ Balanced layer distribution\")\n",
    "    print(\"   ‚Ä¢ High recall with efficient search\")\n",
    "    \n",
    "    print(\"\\n‚ö†Ô∏è Common Degradation Causes:\")\n",
    "    print(\"   1. Point Deletions:\")\n",
    "    print(\"      ‚Ä¢ Remove nodes and their connections\")\n",
    "    print(\"      ‚Ä¢ Can isolate clusters of vectors\")\n",
    "    print(\"      ‚Ä¢ May break optimal search paths\")\n",
    "    \n",
    "    print(\"   2. Frequent Updates:\")\n",
    "    print(\"      ‚Ä¢ Change vector positions in space\")\n",
    "    print(\"      ‚Ä¢ Old connections become suboptimal\")\n",
    "    print(\"      ‚Ä¢ Graph topology lags behind data\")\n",
    "    \n",
    "    print(\"   3. Unbalanced Insertions:\")\n",
    "    print(\"      ‚Ä¢ New vectors in sparse regions\")\n",
    "    print(\"      ‚Ä¢ Poor initial connections\")\n",
    "    print(\"      ‚Ä¢ Uneven graph density\")\n",
    "    \n",
    "    print(\"\\nüìä Degradation Symptoms:\")\n",
    "    print(\"   ‚Ä¢ Reduced recall@k (miss relevant results)\")\n",
    "    print(\"   ‚Ä¢ Increased search latency (longer paths)\")\n",
    "    print(\"   ‚Ä¢ Inconsistent performance across queries\")\n",
    "    print(\"   ‚Ä¢ Higher memory usage per connection\")\n",
    "    \n",
    "    print(\"\\nüîß Healing Strategies:\")\n",
    "    print(\"   1. Index Optimization:\")\n",
    "    print(\"      ‚Ä¢ Reconnect isolated nodes\")\n",
    "    print(\"      ‚Ä¢ Prune poor connections\")\n",
    "    print(\"      ‚Ä¢ Rebalance layer distribution\")\n",
    "    \n",
    "    print(\"   2. Full Rebuild:\")\n",
    "    print(\"      ‚Ä¢ Create fresh index from scratch\")\n",
    "    print(\"      ‚Ä¢ Optimal connections for current data\")\n",
    "    print(\"      ‚Ä¢ Reset to baseline performance\")\n",
    "\n",
    "explain_hnsw_degradation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Setup & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "COLLECTION_NAME = \"workshop_health\"\n",
    "VECTOR_SIZE = 384\n",
    "TARGET_POINTS = 1000  # Reduced size to avoid timeout issues\n",
    "\n",
    "# HNSW Parameters for testing\n",
    "HNSW_CONFIG = {\n",
    "    \"m\": 16,          # Number of bi-directional links for each node\n",
    "    \"ef_construct\": 200,  # Size of dynamic candidate list during construction\n",
    "    \"full_scan_threshold\": 10000  # When to use brute force vs HNSW\n",
    "}\n",
    "\n",
    "# Connect to Qdrant\n",
    "client = get_qdrant_client()\n",
    "\n",
    "print(f\"üîó Connected to Qdrant\")\n",
    "print(f\"üìÅ Collection: {COLLECTION_NAME}\")\n",
    "print(f\"üéØ Target size: {TARGET_POINTS} points\")\n",
    "print(f\"‚öôÔ∏è HNSW config: {HNSW_CONFIG}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèóÔ∏è Build Large-Scale Collection\n",
    "\n",
    "Create a collection with enough points to observe HNSW degradation effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_large_dataset(size: int, seed: int = 42) -> Tuple[pd.DataFrame, np.ndarray]:\n",
    "    \"\"\"Create a large dataset by replicating and adding noise to base data\"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Create base dataset\n",
    "    base_df = create_sample_dataset(size=200, seed=seed)\n",
    "    base_size = len(base_df)\n",
    "    \n",
    "    print(f\"üìä Creating large dataset from {base_size} base samples...\")\n",
    "    \n",
    "    # Calculate how many replications we need\n",
    "    replications = max(1, size // base_size)\n",
    "    remainder = size % base_size\n",
    "    \n",
    "    expanded_data = []\n",
    "    all_vectors = []\n",
    "    point_id = 1\n",
    "    \n",
    "    # Generate base vectors\n",
    "    base_vectors = np.random.randn(base_size, VECTOR_SIZE)\n",
    "    base_vectors = base_vectors / np.linalg.norm(base_vectors, axis=1, keepdims=True)\n",
    "    \n",
    "    for rep in range(replications):\n",
    "        for idx, row in base_df.iterrows():\n",
    "            # Add slight noise to create variations\n",
    "            noise_scale = 0.1 + (rep * 0.05)  # Increase noise with each replication\n",
    "            noise = np.random.normal(0, noise_scale, VECTOR_SIZE)\n",
    "            noisy_vector = base_vectors[idx] + noise\n",
    "            noisy_vector = noisy_vector / np.linalg.norm(noisy_vector)  # Renormalize\n",
    "            \n",
    "            # Create varied text\n",
    "            base_text = row['text']\n",
    "            if rep > 0:\n",
    "                variations = [\n",
    "                    f\"{base_text} (variant {rep})\",\n",
    "                    f\"Updated: {base_text}\",\n",
    "                    f\"{base_text} - version {rep + 1}\",\n",
    "                    f\"Modified {base_text}\"\n",
    "                ]\n",
    "                text = np.random.choice(variations)\n",
    "            else:\n",
    "                text = base_text\n",
    "            \n",
    "            expanded_data.append({\n",
    "                'id': point_id,\n",
    "                'text': text,\n",
    "                'category': row['category'],\n",
    "                'lang': row['lang'],\n",
    "                'timestamp': row['timestamp'] + (rep * 86400),  # Spread timestamps\n",
    "                'replica': rep\n",
    "            })\n",
    "            \n",
    "            all_vectors.append(noisy_vector)\n",
    "            point_id += 1\n",
    "            \n",
    "            if len(expanded_data) >= size:\n",
    "                break\n",
    "        \n",
    "        if len(expanded_data) >= size:\n",
    "            break\n",
    "    \n",
    "    # Handle remainder if needed\n",
    "    if len(expanded_data) < size and remainder > 0:\n",
    "        for idx in range(remainder):\n",
    "            row = base_df.iloc[idx]\n",
    "            noise = np.random.normal(0, 0.2, VECTOR_SIZE)\n",
    "            noisy_vector = base_vectors[idx] + noise\n",
    "            noisy_vector = noisy_vector / np.linalg.norm(noisy_vector)\n",
    "            \n",
    "            expanded_data.append({\n",
    "                'id': point_id,\n",
    "                'text': f\"{row['text']} (final variant)\",\n",
    "                'category': row['category'],\n",
    "                'lang': row['lang'],\n",
    "                'timestamp': row['timestamp'] + (replications * 86400),\n",
    "                'replica': replications\n",
    "            })\n",
    "            \n",
    "            all_vectors.append(noisy_vector)\n",
    "            point_id += 1\n",
    "    \n",
    "    final_df = pd.DataFrame(expanded_data)\n",
    "    final_vectors = np.array(all_vectors)\n",
    "    \n",
    "    print(f\"‚úÖ Created dataset: {len(final_df)} points, {final_vectors.shape[1]}D vectors\")\n",
    "    print(f\"üìä Replications: {replications}, Categories: {final_df['category'].nunique()}\")\n",
    "    \n",
    "    return final_df, final_vectors\n",
    "\n",
    "# Create large dataset\n",
    "print(f\"üèóÔ∏è Building large-scale dataset...\")\n",
    "large_df, large_vectors = create_large_dataset(TARGET_POINTS)\n",
    "\n",
    "print(f\"\\nüìà Dataset statistics:\")\n",
    "print(f\"   Points: {len(large_df)}\")\n",
    "print(f\"   Vector dim: {large_vectors.shape[1]}\")\n",
    "print(f\"   Categories: {large_df['category'].value_counts().to_dict()}\")\n",
    "print(f\"   Replicas: {large_df['replica'].value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèóÔ∏è Create Health Collection with HNSW Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create collection with specific HNSW parameters\n",
    "vector_config = VectorParams(\n",
    "    size=VECTOR_SIZE,\n",
    "    distance=Distance.COSINE,\n",
    "    hnsw_config=HnswConfigDiff(\n",
    "        m=HNSW_CONFIG[\"m\"],\n",
    "        ef_construct=HNSW_CONFIG[\"ef_construct\"],\n",
    "        full_scan_threshold=HNSW_CONFIG[\"full_scan_threshold\"]\n",
    "    )\n",
    ")\n",
    "\n",
    "# Create collection\n",
    "ensure_collection(\n",
    "    client=client,\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    vector_config=vector_config,\n",
    "    force_recreate=True\n",
    ")\n",
    "\n",
    "# Upload data in batches\n",
    "print(f\"\\nüì§ Uploading {len(large_df)} points...\")\n",
    "start_time = time.time()\n",
    "\n",
    "upsert_points_batch(\n",
    "    client=client,\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    df=large_df,\n",
    "    vectors=large_vectors,\n",
    "    payload_cols=['text', 'category', 'lang', 'timestamp', 'replica'],\n",
    "    batch_size=100\n",
    ")\n",
    "\n",
    "upload_time = time.time() - start_time\n",
    "print(f\"\\n‚úÖ Upload complete in {upload_time:.2f}s\")\n",
    "\n",
    "# Verify collection\n",
    "info = client.get_collection(COLLECTION_NAME)\n",
    "print(f\"\\nüìä Collection verification:\")\n",
    "print(f\"   Points: {info.points_count}\")\n",
    "print(f\"   Status: {info.status}\")\n",
    "if hasattr(info.config.params, 'vectors'):\n",
    "    hnsw_config = info.config.params.vectors.hnsw_config\n",
    "    if hnsw_config:\n",
    "        print(f\"   HNSW M: {hnsw_config.m}\")\n",
    "        print(f\"   HNSW ef_construct: {hnsw_config.ef_construct}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Ground Truth Generation\n",
    "\n",
    "Create exact search results for recall measurement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ground_truth_queries(vectors: np.ndarray, n_queries: int = 50, seed: int = 42) -> Tuple[np.ndarray, List[int]]:\n",
    "    \"\"\"Create test queries and their ground truth exact results\"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Select random vectors as queries\n",
    "    query_indices = np.random.choice(len(vectors), size=n_queries, replace=False)\n",
    "    query_vectors = vectors[query_indices]\n",
    "    \n",
    "    print(f\"üéØ Creating ground truth for {n_queries} queries...\")\n",
    "    \n",
    "    ground_truth = []\n",
    "    \n",
    "    for i, query_vector in tqdm(enumerate(query_vectors), desc=\"Computing exact results\", total=len(query_vectors)):\n",
    "        # Get exact top-k using brute force\n",
    "        exact_results = exact_topk(query_vector, vectors, k=20)\n",
    "        # Extract just the indices (the second element is the score)\n",
    "        exact_ids = [idx for idx, score in exact_results]\n",
    "        ground_truth.append(exact_ids)\n",
    "    \n",
    "    print(f\"‚úÖ Ground truth created: {len(ground_truth)} query result sets\")\n",
    "    return query_vectors, ground_truth\n",
    "\n",
    "# Create ground truth (use subset of vectors for faster computation)\n",
    "subset_size = min(2000, len(large_vectors))  # Limit for faster ground truth computation\n",
    "subset_indices = np.random.choice(len(large_vectors), size=subset_size, replace=False)\n",
    "subset_vectors = large_vectors[subset_indices]\n",
    "\n",
    "print(f\"üìä Using subset of {subset_size} vectors for ground truth computation\")\n",
    "query_vectors, ground_truth = create_ground_truth_queries(subset_vectors, n_queries=30)\n",
    "\n",
    "print(f\"\\nüéØ Ground truth sample:\")\n",
    "print(f\"   Query 0 top-5 exact IDs: {ground_truth[0][:5]}\")\n",
    "print(f\"   Query 1 top-5 exact IDs: {ground_truth[1][:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Baseline HNSW Performance\n",
    "\n",
    "Measure recall and latency before any degradation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_search_performance(query_vectors: np.ndarray, ground_truth: List[List[int]], \n",
    "                             ef_search_values: List[int] = [50, 100, 200], k: int = 10) -> Dict:\n",
    "    \"\"\"Measure recall@k and latency for different ef_search values\"\"\"\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for ef_search in ef_search_values:\n",
    "        print(f\"\\nüîç Testing ef_search = {ef_search}\")\n",
    "        \n",
    "        recalls = []\n",
    "        latencies = []\n",
    "        \n",
    "        for i, query_vector in enumerate(query_vectors[:20]):  # Test subset for speed\n",
    "            # Measure latency\n",
    "            start_time = time.time()\n",
    "            \n",
    "            # Search with specific ef_search (this is Qdrant-specific)\n",
    "            try:\n",
    "                search_results = client.search(\n",
    "                    collection_name=COLLECTION_NAME,\n",
    "                    query_vector=query_vector.tolist(),\n",
    "                    limit=k,\n",
    "                    search_params={\"hnsw\": {\"ef\": ef_search}}  # Qdrant-specific parameter\n",
    "                )\n",
    "            except Exception as e:\n",
    "                # Fallback without ef parameter if not supported\n",
    "                search_results = client.search(\n",
    "                    collection_name=COLLECTION_NAME,\n",
    "                    query_vector=query_vector.tolist(),\n",
    "                    limit=k\n",
    "                )\n",
    "            \n",
    "            latency = (time.time() - start_time) * 1000  # Convert to ms\n",
    "            latencies.append(latency)\n",
    "            \n",
    "            # Calculate recall@k\n",
    "            # Note: We need to map back to our subset indices\n",
    "            predicted_ids = []\n",
    "            for result in search_results:\n",
    "                # Find the index in our subset that corresponds to this result\n",
    "                # This is a simplification - in practice you'd maintain proper ID mapping\n",
    "                predicted_ids.append(result.id % len(subset_vectors))  # Map to subset space\n",
    "            \n",
    "            if i < len(ground_truth):\n",
    "                recall = calculate_recall_at_k(predicted_ids, ground_truth[i], k)\n",
    "                recalls.append(recall)\n",
    "        \n",
    "        # Calculate statistics\n",
    "        avg_recall = np.mean(recalls) if recalls else 0\n",
    "        avg_latency = np.mean(latencies)\n",
    "        p95_latency = np.percentile(latencies, 95)\n",
    "        \n",
    "        results[ef_search] = {\n",
    "            'recall@10': avg_recall,\n",
    "            'avg_latency_ms': avg_latency,\n",
    "            'p95_latency_ms': p95_latency,\n",
    "            'queries_tested': len(recalls)\n",
    "        }\n",
    "        \n",
    "        print(f\"   Recall@{k}: {avg_recall:.3f}\")\n",
    "        print(f\"   Avg latency: {avg_latency:.2f}ms\")\n",
    "        print(f\"   P95 latency: {p95_latency:.2f}ms\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Measure baseline performance\n",
    "print(\"üìä Measuring baseline HNSW performance...\")\n",
    "baseline_performance = measure_search_performance(query_vectors, ground_truth)\n",
    "\n",
    "# Display baseline results\n",
    "print(f\"\\nüìà Baseline Performance Summary:\")\n",
    "baseline_df = pd.DataFrame(baseline_performance).T\n",
    "print(baseline_df.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚ö° Simulate Index Churn\n",
    "\n",
    "Create realistic degradation through deletions and updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_index_churn(df: pd.DataFrame, vectors: np.ndarray, \n",
    "                        delete_ratio: float = 0.20, update_ratio: float = 0.15) -> Tuple[List[int], List[PointStruct]]:\n",
    "    \"\"\"Simulate realistic index churn through deletions and updates\"\"\"\n",
    "    \n",
    "    total_points = len(df)\n",
    "    n_deletes = int(total_points * delete_ratio)\n",
    "    n_updates = int(total_points * update_ratio)\n",
    "    \n",
    "    print(f\"üå™Ô∏è Simulating index churn:\")\n",
    "    print(f\"   Total points: {total_points}\")\n",
    "    print(f\"   Deletions: {n_deletes} ({delete_ratio:.1%})\")\n",
    "    print(f\"   Updates: {n_updates} ({update_ratio:.1%})\")\n",
    "    \n",
    "    # Select points to delete (avoid first few for query consistency)\n",
    "    safe_start = 100  # Keep some points safe for testing\n",
    "    delete_candidates = list(range(safe_start, len(df)))\n",
    "    delete_ids = random.sample(delete_candidates, n_deletes)\n",
    "    \n",
    "    # Select points to update (different from delete set)\n",
    "    remaining_candidates = [i for i in delete_candidates if i not in delete_ids]\n",
    "    update_indices = random.sample(remaining_candidates, min(n_updates, len(remaining_candidates)))\n",
    "    \n",
    "    print(f\"\\nüóëÔ∏è Deleting {len(delete_ids)} points...\")\n",
    "    \n",
    "    # Perform deletions in batches\n",
    "    batch_size = 50\n",
    "    for i in tqdm(range(0, len(delete_ids), batch_size), desc=\"Deleting points\"):\n",
    "        batch_ids = delete_ids[i:i + batch_size]\n",
    "        # Map indices to actual IDs\n",
    "        actual_ids = [int(df.iloc[idx]['id']) for idx in batch_ids if idx < len(df)]\n",
    "        if actual_ids:\n",
    "            client.delete(\n",
    "                collection_name=COLLECTION_NAME,\n",
    "                points_selector=[int(x) for x in actual_ids]\n",
    "            )\n",
    "    \n",
    "    print(f\"\\nüîÑ Updating {len(update_indices)} points...\")\n",
    "    \n",
    "    # Create updated points with new vectors\n",
    "    updated_points = []\n",
    "    for idx in update_indices:\n",
    "        if idx < len(df) and idx < len(vectors):\n",
    "            row = df.iloc[idx]\n",
    "            \n",
    "            # Create new vector with significant noise\n",
    "            original_vector = vectors[idx]\n",
    "            noise = np.random.normal(0, 0.3, len(original_vector))  # Significant perturbation\n",
    "            new_vector = original_vector + noise\n",
    "            new_vector = new_vector / np.linalg.norm(new_vector)  # Renormalize\n",
    "            \n",
    "            # Create updated point (cast numpy scalars to native types)\n",
    "            updated_points.append(PointStruct(\n",
    "                id=int(row['id']),\n",
    "                vector=new_vector.tolist(),\n",
    "                payload={\n",
    "                    'text': f\"{str(row['text'])} (updated)\",\n",
    "                    'category': str(row['category']),\n",
    "                    'lang': str(row['lang']),\n",
    "                    'timestamp': int(time.time()),  # Current timestamp\n",
    "                    'replica': int(row['replica'])\n",
    "                }\n",
    "            ))\n",
    "    \n",
    "    # Perform updates in batches\n",
    "    for i in tqdm(range(0, len(updated_points), batch_size), desc=\"Updating points\"):\n",
    "        batch = updated_points[i:i + batch_size]\n",
    "        client.upsert(\n",
    "            collection_name=COLLECTION_NAME,\n",
    "            points=batch\n",
    "        )\n",
    "    \n",
    "    # Generate some new points to simulate fresh inserts\n",
    "    print(f\"\\n‚ûï Adding {n_deletes // 2} new points...\")\n",
    "    new_points = []\n",
    "    max_id = int(df['id'].max()) + 1\n",
    "    \n",
    "    for i in range(n_deletes // 2):\n",
    "        # Random new vector\n",
    "        new_vector = np.random.randn(VECTOR_SIZE)\n",
    "        new_vector = new_vector / np.linalg.norm(new_vector)\n",
    "        \n",
    "        new_points.append(PointStruct(\n",
    "            id=int(max_id + i),\n",
    "            vector=new_vector.tolist(),\n",
    "            payload={\n",
    "                'text': f\"New document {i} added during churn\",\n",
    "                'category': random.choice(['product', 'faq', 'technical']),\n",
    "                'lang': 'en',\n",
    "                'timestamp': int(time.time()),\n",
    "                'replica': -1  # Mark as new\n",
    "            }\n",
    "        ))\n",
    "    \n",
    "    # Insert new points\n",
    "    for i in range(0, len(new_points), batch_size):\n",
    "        batch = new_points[i:i + batch_size]\n",
    "        client.upsert(\n",
    "            collection_name=COLLECTION_NAME,\n",
    "            points=batch\n",
    "        )\n",
    "    \n",
    "    return delete_ids, updated_points + new_points\n",
    "\n",
    "# Simulate churn\n",
    "print(f\"üå™Ô∏è Starting index churn simulation...\")\n",
    "deleted_indices, modified_points = simulate_index_churn(large_df, large_vectors)\n",
    "\n",
    "# Verify churn impact\n",
    "info_after_churn = client.get_collection(COLLECTION_NAME)\n",
    "print(f\"\\nüìä Collection after churn:\")\n",
    "print(f\"   Points before: {len(large_df)}\")\n",
    "print(f\"   Points after: {info_after_churn.points_count}\")\n",
    "print(f\"   Points deleted: {len(deleted_indices)}\")\n",
    "print(f\"   Points modified/added: {len(modified_points)}\")\n",
    "\n",
    "churn_ratio = (len(deleted_indices) + len(modified_points)) / len(large_df)\n",
    "print(f\"   Total churn: {churn_ratio:.1%} of original data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìâ Measure Degradation\n",
    "\n",
    "Compare performance after churn to baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measure performance after churn\n",
    "print(\"üìâ Measuring performance after churn...\")\n",
    "post_churn_performance = measure_search_performance(query_vectors, ground_truth)\n",
    "\n",
    "# Compare performance\n",
    "print(f\"\\nüìä Performance Comparison (Before vs After Churn):\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "comparison_data = []\n",
    "for ef_search in [50, 100, 200]:\n",
    "    if ef_search in baseline_performance and ef_search in post_churn_performance:\n",
    "        baseline = baseline_performance[ef_search]\n",
    "        post_churn = post_churn_performance[ef_search]\n",
    "        \n",
    "        recall_change = (post_churn['recall@10'] - baseline['recall@10']) / baseline['recall@10'] * 100\n",
    "        latency_change = (post_churn['avg_latency_ms'] - baseline['avg_latency_ms']) / baseline['avg_latency_ms'] * 100\n",
    "        \n",
    "        comparison_data.append({\n",
    "            'ef_search': ef_search,\n",
    "            'baseline_recall': baseline['recall@10'],\n",
    "            'post_churn_recall': post_churn['recall@10'],\n",
    "            'recall_change_%': recall_change,\n",
    "            'baseline_latency_ms': baseline['avg_latency_ms'],\n",
    "            'post_churn_latency_ms': post_churn['avg_latency_ms'],\n",
    "            'latency_change_%': latency_change\n",
    "        })\n",
    "        \n",
    "        print(f\"\\nef_search = {ef_search}:\")\n",
    "        print(f\"   Recall@10: {baseline['recall@10']:.3f} ‚Üí {post_churn['recall@10']:.3f} ({recall_change:+.1f}%)\")\n",
    "        print(f\"   Avg Latency: {baseline['avg_latency_ms']:.2f}ms ‚Üí {post_churn['avg_latency_ms']:.2f}ms ({latency_change:+.1f}%)\")\n",
    "        \n",
    "        if recall_change < -5:\n",
    "            print(f\"   ‚ö†Ô∏è  Significant recall degradation detected!\")\n",
    "        if latency_change > 20:\n",
    "            print(f\"   ‚ö†Ô∏è  Significant latency increase detected!\")\n",
    "\n",
    "# Create comparison DataFrame\n",
    "if comparison_data:\n",
    "    comparison_df = pd.DataFrame(comparison_data)\n",
    "    print(f\"\\nüìã Degradation Summary:\")\n",
    "    print(comparison_df.round(3))\n",
    "    \n",
    "    # Overall degradation assessment\n",
    "    avg_recall_degradation = comparison_df['recall_change_%'].mean()\n",
    "    avg_latency_increase = comparison_df['latency_change_%'].mean()\n",
    "    \n",
    "    print(f\"\\nüéØ Overall Index Health:\")\n",
    "    print(f\"   Average recall degradation: {avg_recall_degradation:.1f}%\")\n",
    "    print(f\"   Average latency increase: {avg_latency_increase:.1f}%\")\n",
    "    \n",
    "    if avg_recall_degradation < -10 or avg_latency_increase > 25:\n",
    "        print(f\"   üö® Index healing recommended!\")\n",
    "    elif avg_recall_degradation < -5 or avg_latency_increase > 15:\n",
    "        print(f\"   ‚ö†Ô∏è  Index performance declining, consider healing\")\n",
    "    else:\n",
    "        print(f\"   ‚úÖ Index health acceptable\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No comparison data available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Index Healing/Optimization\n",
    "\n",
    "Apply healing strategies to restore index performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_index_healing(collection_name: str, method: str = \"optimize\"):\n",
    "    \"\"\"Perform index healing using available methods\"\"\"\n",
    "    \n",
    "    print(f\"üîß Performing index healing: {method}\")\n",
    "    \n",
    "    if method == \"optimize\":\n",
    "        print(\"   Attempting collection optimization...\")\n",
    "        try:\n",
    "            # This is the preferred method if available\n",
    "            # Note: API may vary by Qdrant version\n",
    "            optimization_result = client.update_collection(\n",
    "                collection_name=collection_name,\n",
    "                optimizer_config=OptimizersConfigDiff(\n",
    "                    indexing_threshold=0,  # Force immediate indexing\n",
    "                )\n",
    "            )\n",
    "            print(f\"   ‚úÖ Optimization triggered successfully\")\n",
    "            \n",
    "            # Wait for optimization to complete\n",
    "            print(\"   ‚è≥ Waiting for optimization to complete...\")\n",
    "            time.sleep(10)  # Give some time for processing\n",
    "            \n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ö†Ô∏è Optimization method failed: {e}\")\n",
    "            print(f\"   üîÑ Falling back to rebuild method\")\n",
    "            method = \"rebuild\"\n",
    "    \n",
    "    if method == \"rebuild\":\n",
    "        print(\"   Performing index rebuild...\")\n",
    "        try:\n",
    "            # Get current collection info and data\n",
    "            collection_info = client.get_collection(collection_name)\n",
    "            \n",
    "            # Scroll through all points to backup\n",
    "            print(\"   üì§ Backing up collection data...\")\n",
    "            all_points = []\n",
    "            offset = None\n",
    "            \n",
    "            while True:\n",
    "                scroll_result = client.scroll(\n",
    "                    collection_name=collection_name,\n",
    "                    limit=1000,\n",
    "                    offset=offset,\n",
    "                    with_vectors=True,\n",
    "                    with_payload=True\n",
    "                )\n",
    "                points, next_offset = scroll_result\n",
    "                \n",
    "                if not points:\n",
    "                    break\n",
    "                \n",
    "                all_points.extend(points)\n",
    "                offset = next_offset\n",
    "                \n",
    "                if next_offset is None:\n",
    "                    break\n",
    "            \n",
    "            print(f\"   üìä Backed up {len(all_points)} points\")\n",
    "            \n",
    "            # Recreate collection\n",
    "            temp_collection = f\"{collection_name}_temp\"\n",
    "            client.recreate_collection(\n",
    "                collection_name=temp_collection,\n",
    "                vectors_config=collection_info.config.params.vectors,\n",
    "                hnsw_config=collection_info.config.params.vectors.hnsw_config\n",
    "            )\n",
    "            \n",
    "            # Restore data in batches\n",
    "            print(\"   üì• Restoring data to fresh index...\")\n",
    "            batch_size = 100\n",
    "            \n",
    "            for i in tqdm(range(0, len(all_points), batch_size), desc=\"Restoring\"):\n",
    "                batch = all_points[i:i + batch_size]\n",
    "                client.upsert(\n",
    "                    collection_name=temp_collection,\n",
    "                    points=batch\n",
    "                )\n",
    "            \n",
    "            # Swap collections (delete old, rename new)\n",
    "            client.delete_collection(collection_name)\n",
    "            \n",
    "            # Rename temp collection (this might not be available in all versions)\n",
    "            try:\n",
    "                # If rename is available\n",
    "                client.update_collection(\n",
    "                    collection_name=temp_collection,\n",
    "                    # Rename operation - this API may not exist\n",
    "                )\n",
    "            except:\n",
    "                # Fallback: recreate original and copy data\n",
    "                client.recreate_collection(\n",
    "                    collection_name=collection_name,\n",
    "                    vectors_config=collection_info.config.params.vectors,\n",
    "                    hnsw_config=collection_info.config.params.vectors.hnsw_config\n",
    "                )\n",
    "                \n",
    "                # Copy all points to original name\n",
    "                for i in tqdm(range(0, len(all_points), batch_size), desc=\"Final restore\"):\n",
    "                    batch = all_points[i:i + batch_size]\n",
    "                    client.upsert(\n",
    "                        collection_name=collection_name,\n",
    "                        points=batch\n",
    "                    )\n",
    "                \n",
    "                # Clean up temp collection\n",
    "                client.delete_collection(temp_collection)\n",
    "            \n",
    "            print(f\"   ‚úÖ Index rebuild completed\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Rebuild failed: {e}\")\n",
    "            return False\n",
    "    \n",
    "    return False\n",
    "\n",
    "# Perform healing\n",
    "healing_start = time.time()\n",
    "healing_success = perform_index_healing(COLLECTION_NAME, method=\"optimize\")\n",
    "healing_time = time.time() - healing_start\n",
    "\n",
    "print(f\"\\n‚è±Ô∏è Healing completed in {healing_time:.2f}s\")\n",
    "\n",
    "if healing_success:\n",
    "    # Verify collection after healing\n",
    "    info_after_healing = client.get_collection(COLLECTION_NAME)\n",
    "    print(f\"\\nüìä Collection after healing:\")\n",
    "    print(f\"   Points: {info_after_healing.points_count}\")\n",
    "    print(f\"   Status: {info_after_healing.status}\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è Healing was not successful, proceeding with degraded index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü©∫ Post-Healing Performance Measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measure performance after healing\n",
    "print(\"ü©∫ Measuring performance after healing...\")\n",
    "post_healing_performance = measure_search_performance(query_vectors, ground_truth)\n",
    "\n",
    "# Compare all three phases\n",
    "print(f\"\\nüìä Complete Performance Analysis:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "phases = {\n",
    "    'Baseline': baseline_performance,\n",
    "    'Post-Churn': post_churn_performance,\n",
    "    'Post-Healing': post_healing_performance\n",
    "}\n",
    "\n",
    "complete_analysis = []\n",
    "\n",
    "for ef_search in [50, 100, 200]:\n",
    "    print(f\"\\nüîç ef_search = {ef_search}:\")\n",
    "    \n",
    "    phase_data = {'ef_search': ef_search}\n",
    "    \n",
    "    for phase_name, phase_results in phases.items():\n",
    "        if ef_search in phase_results:\n",
    "            recall = phase_results[ef_search]['recall@10']\n",
    "            latency = phase_results[ef_search]['avg_latency_ms']\n",
    "            \n",
    "            phase_data[f'{phase_name.lower()}_recall'] = recall\n",
    "            phase_data[f'{phase_name.lower()}_latency'] = latency\n",
    "            \n",
    "            print(f\"   {phase_name:>12}: Recall {recall:.3f}, Latency {latency:.2f}ms\")\n",
    "    \n",
    "    # Calculate healing effectiveness\n",
    "    if 'baseline_recall' in phase_data and 'post-healing_recall' in phase_data:\n",
    "        healing_recovery = (\n",
    "            (phase_data['post-healing_recall'] - phase_data['post-churn_recall']) /\n",
    "            (phase_data['baseline_recall'] - phase_data['post-churn_recall']) * 100\n",
    "        ) if phase_data['baseline_recall'] != phase_data['post-churn_recall'] else 100\n",
    "        \n",
    "        phase_data['healing_recovery_%'] = healing_recovery\n",
    "        print(f\"   {'Recovery':>12}: {healing_recovery:.1f}% of degradation recovered\")\n",
    "    \n",
    "    complete_analysis.append(phase_data)\n",
    "\n",
    "# Create comprehensive analysis DataFrame\n",
    "if complete_analysis:\n",
    "    analysis_df = pd.DataFrame(complete_analysis)\n",
    "    print(f\"\\nüìã Comprehensive Analysis Table:\")\n",
    "    print(analysis_df.round(3))\n",
    "    \n",
    "    # Summary statistics\n",
    "    print(f\"\\nüéØ Healing Effectiveness Summary:\")\n",
    "    if 'healing_recovery_%' in analysis_df.columns:\n",
    "        avg_recovery = analysis_df['healing_recovery_%'].mean()\n",
    "        print(f\"   Average recovery: {avg_recovery:.1f}%\")\n",
    "        \n",
    "        if avg_recovery > 80:\n",
    "            print(f\"   ‚úÖ Excellent healing effectiveness\")\n",
    "        elif avg_recovery > 60:\n",
    "            print(f\"   ‚úÖ Good healing effectiveness\")\n",
    "        elif avg_recovery > 40:\n",
    "            print(f\"   ‚ö†Ô∏è Moderate healing effectiveness\")\n",
    "        else:\n",
    "            print(f\"   ‚ùå Poor healing effectiveness\")\n",
    "    \n",
    "    # Performance comparison\n",
    "    baseline_avg_recall = analysis_df['baseline_recall'].mean()\n",
    "    healed_avg_recall = analysis_df['post-healing_recall'].mean()\n",
    "    final_degradation = (healed_avg_recall - baseline_avg_recall) / baseline_avg_recall * 100\n",
    "    \n",
    "    print(f\"\\nüìà Final Index Health:\")\n",
    "    print(f\"   Baseline avg recall: {baseline_avg_recall:.3f}\")\n",
    "    print(f\"   Post-healing avg recall: {healed_avg_recall:.3f}\")\n",
    "    print(f\"   Final degradation: {final_degradation:+.1f}%\")\n",
    "    \n",
    "    if abs(final_degradation) < 2:\n",
    "        print(f\"   ‚úÖ Index fully restored to baseline performance\")\n",
    "    elif abs(final_degradation) < 5:\n",
    "        print(f\"   ‚úÖ Index mostly restored, minor degradation remains\")\n",
    "    else:\n",
    "        print(f\"   ‚ö†Ô∏è Significant degradation remains after healing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà Performance Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if complete_analysis:\n",
    "    # Create visualization\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    fig.suptitle('HNSW Index Health Analysis', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    df = pd.DataFrame(complete_analysis)\n",
    "    ef_values = df['ef_search'].values\n",
    "    \n",
    "    # Colors for phases\n",
    "    colors = ['#2ecc71', '#e74c3c', '#3498db']  # Green, Red, Blue\n",
    "    phase_names = ['Baseline', 'Post-Churn', 'Post-Healing']\n",
    "    \n",
    "    # 1. Recall comparison\n",
    "    ax1.plot(ef_values, df['baseline_recall'], 'o-', color=colors[0], label='Baseline', linewidth=2, markersize=8)\n",
    "    ax1.plot(ef_values, df['post-churn_recall'], 's-', color=colors[1], label='Post-Churn', linewidth=2, markersize=8)\n",
    "    ax1.plot(ef_values, df['post-healing_recall'], '^-', color=colors[2], label='Post-Healing', linewidth=2, markersize=8)\n",
    "    ax1.set_xlabel('ef_search')\n",
    "    ax1.set_ylabel('Recall@10')\n",
    "    ax1.set_title('Recall Performance Across Index States')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.set_ylim(0, 1)\n",
    "    \n",
    "    # 2. Latency comparison\n",
    "    ax2.plot(ef_values, df['baseline_latency'], 'o-', color=colors[0], label='Baseline', linewidth=2, markersize=8)\n",
    "    ax2.plot(ef_values, df['post-churn_latency'], 's-', color=colors[1], label='Post-Churn', linewidth=2, markersize=8)\n",
    "    ax2.plot(ef_values, df['post-healing_latency'], '^-', color=colors[2], label='Post-Healing', linewidth=2, markersize=8)\n",
    "    ax2.set_xlabel('ef_search')\n",
    "    ax2.set_ylabel('Average Latency (ms)')\n",
    "    ax2.set_title('Latency Performance Across Index States')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Recall degradation and recovery\n",
    "    x_pos = np.arange(len(ef_values))\n",
    "    width = 0.35\n",
    "    \n",
    "    # Calculate degradation percentages\n",
    "    churn_degradation = ((df['post-churn_recall'] - df['baseline_recall']) / df['baseline_recall'] * 100).values\n",
    "    healing_improvement = ((df['post-healing_recall'] - df['post-churn_recall']) / df['baseline_recall'] * 100).values\n",
    "    \n",
    "    ax3.bar(x_pos - width/2, churn_degradation, width, label='Churn Impact', color=colors[1], alpha=0.7)\n",
    "    ax3.bar(x_pos + width/2, healing_improvement, width, label='Healing Recovery', color=colors[2], alpha=0.7)\n",
    "    ax3.set_xlabel('ef_search')\n",
    "    ax3.set_ylabel('Recall Change (%)')\n",
    "    ax3.set_title('Index Degradation and Recovery')\n",
    "    ax3.set_xticks(x_pos)\n",
    "    ax3.set_xticklabels(ef_values)\n",
    "    ax3.legend()\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    ax3.axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "    \n",
    "    # 4. Recall vs Latency trade-off\n",
    "    # Show the trade-off for each phase\n",
    "    ax4.scatter(df['baseline_latency'], df['baseline_recall'], c=colors[0], s=100, alpha=0.7, label='Baseline')\n",
    "    ax4.scatter(df['post-churn_latency'], df['post-churn_recall'], c=colors[1], s=100, alpha=0.7, label='Post-Churn')\n",
    "    ax4.scatter(df['post-healing_latency'], df['post-healing_recall'], c=colors[2], s=100, alpha=0.7, label='Post-Healing')\n",
    "    \n",
    "    # Connect points for same ef_search values\n",
    "    for i in range(len(df)):\n",
    "        ax4.plot([df['baseline_latency'].iloc[i], df['post-churn_latency'].iloc[i]], \n",
    "                [df['baseline_recall'].iloc[i], df['post-churn_recall'].iloc[i]], \n",
    "                'r--', alpha=0.5, linewidth=1)\n",
    "        ax4.plot([df['post-churn_latency'].iloc[i], df['post-healing_latency'].iloc[i]], \n",
    "                [df['post-churn_recall'].iloc[i], df['post-healing_recall'].iloc[i]], \n",
    "                'b--', alpha=0.5, linewidth=1)\n",
    "    \n",
    "    ax4.set_xlabel('Average Latency (ms)')\n",
    "    ax4.set_ylabel('Recall@10')\n",
    "    ax4.set_title('Recall vs Latency Trade-off')\n",
    "    ax4.legend()\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nüìä Chart Interpretation:\")\n",
    "    print(\"   ‚Ä¢ Top-left: Recall degradation and recovery across ef_search values\")\n",
    "    print(\"   ‚Ä¢ Top-right: Latency changes during churn and healing\")\n",
    "    print(\"   ‚Ä¢ Bottom-left: Quantifies degradation (red) vs recovery (blue)\")\n",
    "    print(\"   ‚Ä¢ Bottom-right: Shows recall-latency trade-offs for each phase\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No complete analysis data available for visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß HNSW Parameter Tuning Guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hnsw_tuning_guide():\n",
    "    \"\"\"Comprehensive guide for HNSW parameter tuning\"\"\"\n",
    "    \n",
    "    print(\"üîß HNSW Parameter Tuning Guide\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    print(\"\\nüìä Key HNSW Parameters:\")\n",
    "    \n",
    "    params = {\n",
    "        \"M (max connections)\": {\n",
    "            \"description\": \"Maximum bi-directional links per node\",\n",
    "            \"range\": \"4-64 (typical: 16-32)\",\n",
    "            \"impact\": \"Higher = better recall, more memory\",\n",
    "            \"tuning\": \"Start with 16, increase if recall insufficient\"\n",
    "        },\n",
    "        \"ef_construct\": {\n",
    "            \"description\": \"Dynamic candidate list size during construction\", \n",
    "            \"range\": \"100-800 (typical: 200-400)\",\n",
    "            \"impact\": \"Higher = better quality, slower indexing\",\n",
    "            \"tuning\": \"2-4x your target ef_search value\"\n",
    "        },\n",
    "        \"ef_search\": {\n",
    "            \"description\": \"Dynamic candidate list size during search\",\n",
    "            \"range\": \"10-500+ (typical: 50-200)\", \n",
    "            \"impact\": \"Higher = better recall, slower search\",\n",
    "            \"tuning\": \"Tune based on recall/latency requirements\"\n",
    "        },\n",
    "        \"full_scan_threshold\": {\n",
    "            \"description\": \"Switch to brute force below this size\",\n",
    "            \"range\": \"1000-50000\",\n",
    "            \"impact\": \"Affects small collection performance\",\n",
    "            \"tuning\": \"Set based on expected collection size\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    for param, info in params.items():\n",
    "        print(f\"\\nüéõÔ∏è {param}:\")\n",
    "        print(f\"   üìñ {info['description']}\")\n",
    "        print(f\"   üìè Range: {info['range']}\")\n",
    "        print(f\"   ‚ö° Impact: {info['impact']}\")\n",
    "        print(f\"   üéØ Tuning: {info['tuning']}\")\n",
    "    \n",
    "    print(f\"\\nüéØ Tuning Strategy:\")\n",
    "    print(f\"\\n1Ô∏è‚É£ BASELINE ESTABLISHMENT:\")\n",
    "    print(f\"   ‚Ä¢ Start with M=16, ef_construct=200\")\n",
    "    print(f\"   ‚Ä¢ Test ef_search values: 50, 100, 200\")\n",
    "    print(f\"   ‚Ä¢ Measure baseline recall and latency\")\n",
    "    \n",
    "    print(f\"\\n2Ô∏è‚É£ RECALL OPTIMIZATION:\")\n",
    "    print(f\"   ‚Ä¢ If recall < target ‚Üí increase M or ef_search\")\n",
    "    print(f\"   ‚Ä¢ If building from scratch ‚Üí increase ef_construct\")\n",
    "    print(f\"   ‚Ä¢ Consider data distribution and dimensionality\")\n",
    "    \n",
    "    print(f\"\\n3Ô∏è‚É£ LATENCY OPTIMIZATION:\")\n",
    "    print(f\"   ‚Ä¢ If latency too high ‚Üí decrease ef_search\")\n",
    "    print(f\"   ‚Ä¢ If memory usage high ‚Üí decrease M\")\n",
    "    print(f\"   ‚Ä¢ Balance recall requirements with performance\")\n",
    "    \n",
    "    print(f\"\\n4Ô∏è‚É£ PRODUCTION CONSIDERATIONS:\")\n",
    "    print(f\"   ‚Ä¢ Monitor recall degradation over time\")\n",
    "    print(f\"   ‚Ä¢ Set up automated health checks\")\n",
    "    print(f\"   ‚Ä¢ Plan healing/rebuild schedules\")\n",
    "    print(f\"   ‚Ä¢ Consider different parameters per use case\")\n",
    "    \n",
    "    print(f\"\\nüìà Performance Guidelines:\")\n",
    "    \n",
    "    scenarios = {\n",
    "        \"High Precision Search\": {\n",
    "            \"params\": \"M=32, ef_construct=400, ef_search=200\",\n",
    "            \"trade_off\": \"Best recall, higher latency/memory\"\n",
    "        },\n",
    "        \"Balanced Performance\": {\n",
    "            \"params\": \"M=16, ef_construct=200, ef_search=100\",\n",
    "            \"trade_off\": \"Good recall-latency balance\"\n",
    "        },\n",
    "        \"Low Latency Search\": {\n",
    "            \"params\": \"M=8, ef_construct=100, ef_search=50\",\n",
    "            \"trade_off\": \"Fast search, moderate recall\"\n",
    "        },\n",
    "        \"Memory Constrained\": {\n",
    "            \"params\": \"M=8, ef_construct=150, ef_search=75\",\n",
    "            \"trade_off\": \"Lower memory usage, some recall loss\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    for scenario, config in scenarios.items():\n",
    "        print(f\"\\nüé™ {scenario}:\")\n",
    "        print(f\"   ‚öôÔ∏è Params: {config['params']}\")\n",
    "        print(f\"   ‚öñÔ∏è Trade-off: {config['trade_off']}\")\n",
    "\n",
    "hnsw_tuning_guide()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Production Monitoring Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_monitoring_strategy():\n",
    "    \"\"\"Production monitoring strategy for HNSW index health\"\"\"\n",
    "    \n",
    "    print(\"üìä Production HNSW Monitoring Strategy\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    print(\"\\nüéØ Key Health Metrics:\")\n",
    "    \n",
    "    metrics = {\n",
    "        \"Recall Proxy\": {\n",
    "            \"method\": \"Compare ef_search=50 vs ef_search=400 overlap\",\n",
    "            \"frequency\": \"Every hour\",\n",
    "            \"alert_threshold\": \"< 80% overlap\",\n",
    "            \"description\": \"Detects recall degradation without ground truth\"\n",
    "        },\n",
    "        \"Search Latency\": {\n",
    "            \"method\": \"P50, P95, P99 response times\",\n",
    "            \"frequency\": \"Real-time\",\n",
    "            \"alert_threshold\": \"P95 > 2x baseline\",\n",
    "            \"description\": \"Indicates graph connectivity issues\"\n",
    "        },\n",
    "        \"Result Consistency\": {\n",
    "            \"method\": \"Track repeated query result stability\",\n",
    "            \"frequency\": \"Every 15 minutes\",\n",
    "            \"alert_threshold\": \"< 95% consistency\",\n",
    "            \"description\": \"Detects index instability from updates\"\n",
    "        },\n",
    "        \"Churn Rate\": {\n",
    "            \"method\": \"Monitor insert/update/delete rates\",\n",
    "            \"frequency\": \"Every 5 minutes\", \n",
    "            \"alert_threshold\": \"> 10% collection size/hour\",\n",
    "            \"description\": \"High churn predicts future degradation\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    for metric, config in metrics.items():\n",
    "        print(f\"\\nüìà {metric}:\")\n",
    "        print(f\"   üîç Method: {config['method']}\")\n",
    "        print(f\"   ‚è∞ Frequency: {config['frequency']}\")\n",
    "        print(f\"   üö® Alert: {config['alert_threshold']}\")\n",
    "        print(f\"   üí≠ Purpose: {config['description']}\")\n",
    "    \n",
    "    print(f\"\\nüö® Alert Levels:\")\n",
    "    \n",
    "    alert_levels = {\n",
    "        \"üü¢ Healthy\": {\n",
    "            \"conditions\": \"All metrics within normal ranges\",\n",
    "            \"action\": \"Continue normal monitoring\"\n",
    "        },\n",
    "        \"üü° Warning\": {\n",
    "            \"conditions\": \"1-2 metrics showing degradation\", \n",
    "            \"action\": \"Increase monitoring frequency, plan healing\"\n",
    "        },\n",
    "        \"üü† Degraded\": {\n",
    "            \"conditions\": \"Multiple metrics affected, user impact likely\",\n",
    "            \"action\": \"Schedule immediate index healing\"\n",
    "        },\n",
    "        \"üî¥ Critical\": {\n",
    "            \"conditions\": \"Severe degradation, significant user impact\",\n",
    "            \"action\": \"Emergency index rebuild, investigate cause\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    for level, config in alert_levels.items():\n",
    "        print(f\"\\n{level}:\")\n",
    "        print(f\"   üìä Conditions: {config['conditions']}\")\n",
    "        print(f\"   üîß Action: {config['action']}\")\n",
    "    \n",
    "    print(f\"\\nüõ†Ô∏è Automated Responses:\")\n",
    "    \n",
    "    responses = {\n",
    "        \"Proactive Healing\": \"Trigger optimization when churn > threshold\",\n",
    "        \"Dynamic ef_search\": \"Increase ef_search temporarily during degradation\",\n",
    "        \"Load Balancing\": \"Route traffic to healthier replicas\",\n",
    "        \"Graceful Degradation\": \"Fall back to exact search for critical queries\"\n",
    "    }\n",
    "    \n",
    "    for response, description in responses.items():\n",
    "        print(f\"   ‚Ä¢ {response}: {description}\")\n",
    "    \n",
    "    print(f\"\\nüìÖ Maintenance Schedule:\")\n",
    "    \n",
    "    schedule = {\n",
    "        \"Daily\": \"Review health metrics, check alert logs\",\n",
    "        \"Weekly\": \"Analyze performance trends, tune parameters\",\n",
    "        \"Monthly\": \"Full index health assessment, capacity planning\",\n",
    "        \"Quarterly\": \"Benchmark against new HNSW versions/settings\"\n",
    "    }\n",
    "    \n",
    "    for frequency, task in schedule.items():\n",
    "        print(f\"   üóìÔ∏è {frequency}: {task}\")\n",
    "\n",
    "create_monitoring_strategy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìã Final Summary & Best Practices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final collection status\n",
    "final_info = client.get_collection(COLLECTION_NAME)\n",
    "\n",
    "print(\"üéâ HNSW Index Health Workshop Summary\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(f\"\\nüìö Collection: {COLLECTION_NAME}\")\n",
    "print(f\"   üìä Final point count: {final_info.points_count}\")\n",
    "print(f\"   ‚öôÔ∏è HNSW configuration: M={HNSW_CONFIG['m']}, ef_construct={HNSW_CONFIG['ef_construct']}\")\n",
    "print(f\"   üå™Ô∏è Churn simulation: {len(deleted_indices)} deleted, {len(modified_points)} modified\")\n",
    "print(f\"   ‚è±Ô∏è Healing time: {healing_time:.2f}s\")\n",
    "\n",
    "print(f\"\\nüîç Analysis Performed:\")\n",
    "print(\"   ‚úÖ Baseline performance measurement\")\n",
    "print(\"   ‚úÖ Index churn simulation (deletions + updates)\")\n",
    "print(\"   ‚úÖ Degradation quantification\")\n",
    "print(\"   ‚úÖ Healing/optimization process\")\n",
    "print(\"   ‚úÖ Recovery effectiveness analysis\")\n",
    "\n",
    "if 'complete_analysis' in locals() and complete_analysis:\n",
    "    df = pd.DataFrame(complete_analysis)\n",
    "    avg_baseline_recall = df['baseline_recall'].mean()\n",
    "    avg_degraded_recall = df['post-churn_recall'].mean()\n",
    "    avg_healed_recall = df['post-healing_recall'].mean()\n",
    "    \n",
    "    print(f\"\\nüìä Performance Summary:\")\n",
    "    print(f\"   Baseline recall: {avg_baseline_recall:.3f}\")\n",
    "    print(f\"   Post-churn recall: {avg_degraded_recall:.3f} ({(avg_degraded_recall-avg_baseline_recall)/avg_baseline_recall*100:+.1f}%)\")\n",
    "    print(f\"   Post-healing recall: {avg_healed_recall:.3f} ({(avg_healed_recall-avg_baseline_recall)/avg_baseline_recall*100:+.1f}%)\")\n",
    "    \n",
    "    if 'healing_recovery_%' in df.columns:\n",
    "        avg_recovery = df['healing_recovery_%'].mean()\n",
    "        print(f\"   Healing effectiveness: {avg_recovery:.1f}% recovery\")\n",
    "\n",
    "print(f\"\\nüéØ Key Learnings:\")\n",
    "print(\"   üîπ HNSW indexes degrade with heavy churn (updates/deletes)\")\n",
    "print(\"   üîπ Degradation manifests as reduced recall and increased latency\")\n",
    "print(\"   üîπ Regular optimization/healing can restore performance\")\n",
    "print(\"   üîπ Proactive monitoring prevents severe degradation\")\n",
    "print(\"   üîπ Parameter tuning balances recall, latency, and memory\")\n",
    "\n",
    "print(f\"\\nüõ†Ô∏è Production Best Practices:\")\n",
    "print(\"   üìä Monitor recall proxy metrics (ef_search overlap)\")\n",
    "print(\"   ‚è∞ Track latency percentiles (P95, P99)\")\n",
    "print(\"   üîÑ Schedule regular index optimization\")\n",
    "print(\"   üö® Set up automated degradation alerts\")\n",
    "print(\"   üìà Tune HNSW parameters for your workload\")\n",
    "print(\"   üíæ Plan for index rebuilds during major degradation\")\n",
    "\n",
    "print(f\"\\nüöÄ Next Steps:\")\n",
    "print(\"   ‚Ä¢ Implement monitoring dashboards\")\n",
    "print(\"   ‚Ä¢ Set up automated healing triggers\")\n",
    "print(\"   ‚Ä¢ Benchmark different HNSW parameters\")\n",
    "print(\"   ‚Ä¢ Test healing strategies in staging\")\n",
    "print(\"   ‚Ä¢ Document runbooks for production issues\")\n",
    "\n",
    "print(f\"\\n‚ú® Workshop complete! You now understand HNSW index health management.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üßπ Cleanup (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to clean up the large collection\n",
    "# PRESERVE_COLLECTIONS = True  # Set to False to delete\n",
    "\n",
    "# if not PRESERVE_COLLECTIONS:\n",
    "#     try:\n",
    "#         client.delete_collection(COLLECTION_NAME)\n",
    "#         print(f\"üóëÔ∏è Deleted collection: {COLLECTION_NAME}\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"Note: Could not delete collection: {e}\")\n",
    "# else:\n",
    "#     print(f\"üíæ Collection preserved: {COLLECTION_NAME}\")\n",
    "\n",
    "print(f\"\\nüéâ HNSW Index Health workshop complete!\")\n",
    "print(f\"\\nüöÄ Ready for Notebook 5: Agentic RAG!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
