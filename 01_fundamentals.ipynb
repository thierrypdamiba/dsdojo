{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 1: Qdrant Fundamentals & Search Basics\n",
    "\n",
    "## üéØ Objectives\n",
    "\n",
    "In this notebook, you'll learn:\n",
    "- How to connect to Qdrant Cloud with your own credentials\n",
    "- Create collections with vector configurations\n",
    "- Ingest documents with metadata (payload)\n",
    "- Perform basic vector searches\n",
    "- Use filtering with payload indexes\n",
    "- Understand core Qdrant concepts: collections, points, vectors, payload\n",
    "\n",
    "## üìã Prerequisites\n",
    "\n",
    "- `qdrant-client=1.15`, `numpy`, `pandas`, `tqdm`\n",
    "- Required environment variables: `QDRANT_URL`, `QDRANT_API_KEY`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to connect to the remote Jupyter Server 'http://127.0.0.1:8888/'. Verify the server is running and reachable. (Failed to connect to the remote Jupyter Server 'http://127.0.0.1:8888/'. Verify the server is running and reachable. (request to http://127.0.0.1:8888/api/kernels?1755571481435 failed, reason: connect ECONNREFUSED 127.0.0.1:8888).)."
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils import (\n",
    "    ensure_collection, create_sample_dataset,\n",
    "    upsert_points_batch, search_dense, print_search_results,\n",
    "    create_payload_index, print_system_info\n",
    ")\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import VectorParams, Distance, Filter, FieldCondition, MatchValue\n",
    "\n",
    "print_system_info()\n",
    "print(f\"\\nüìç Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Auto-Install Dependencies\n",
    "\n",
    "The cell below will automatically install any missing packages. Perfect for JupyterLab environments!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (will skip if already installed)\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_if_missing(package_name, import_name=None):\n",
    "    \"\"\"Install package if not already available\"\"\"\n",
    "    if import_name is None:\n",
    "        import_name = package_name.replace('-', '_')\n",
    "    \n",
    "    try:\n",
    "        __import__(import_name)\n",
    "        print(f\"‚úÖ {package_name} already available\")\n",
    "        return True\n",
    "    except ImportError:\n",
    "        print(f\"üì¶ Installing {package_name}...\")\n",
    "        try:\n",
    "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package_name, \"-q\"])\n",
    "            print(f\"‚úÖ {package_name} installed successfully\")\n",
    "            return True\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"‚ùå Failed to install {package_name}: {e}\")\n",
    "            return False\n",
    "\n",
    "# Required packages for this notebook\n",
    "required_packages = [\n",
    "    (\"qdrant-client\", \"qdrant_client\"),\n",
    "    (\"pandas\", \"pandas\"),\n",
    "    (\"numpy\", \"numpy\"), \n",
    "    (\"tqdm\", \"tqdm\"),\n",
    "    (\"matplotlib\", \"matplotlib\")\n",
    "]\n",
    "\n",
    "print(\"üîß Checking and installing dependencies...\")\n",
    "all_installed = True\n",
    "for package, import_name in required_packages:\n",
    "    if not install_if_missing(package, import_name):\n",
    "        all_installed = False\n",
    "\n",
    "if all_installed:\n",
    "    print(\"\\nüéâ All dependencies ready!\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è Some packages failed to install. You may need to install them manually.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Qdrant Cloud Setup (Required)\n",
    "\n",
    "For this notebook, you must use your own Qdrant Cloud cluster.\n",
    "\n",
    "- Sign up and create a free cluster at: [cloud.qdrant.io](https://cloud.qdrant.io)\n",
    "- Obtain your cluster URL and API key, then set these environment variables before connecting:\n",
    "\n",
    "```python\n",
    "import os\n",
    "os.environ[\"QDRANT_URL\"] = \"https://your-cluster.qdrant.io:6333\"\n",
    "os.environ[\"QDRANT_API_KEY\"] = \"your-api-key\"\n",
    "```\n",
    "\n",
    "No shared webinar cluster is provided in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Workshop Configuration\n",
    "COLLECTION_NAME = \"workshop_fundamentals\"\n",
    "VECTOR_SIZE = 384  # Compatible with many embedding models\n",
    "\n",
    "print(\"üîê Qdrant Cloud Setup (Your Own Credentials)\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Require user-provided cluster credentials\n",
    "custom_url = os.getenv(\"QDRANT_URL\")\n",
    "custom_key = os.getenv(\"QDRANT_API_KEY\")\n",
    "\n",
    "if not custom_url or not custom_key:\n",
    "    raise RuntimeError(\n",
    "        \"QDRANT_URL and QDRANT_API_KEY must be set. Create a free cluster at https://cloud.qdrant.io, \"\n",
    "        \"then set the environment variables as shown in the previous cell.\"\n",
    "    )\n",
    "\n",
    "print(\"üåê Using your Qdrant Cloud cluster\")\n",
    "print(f\"   URL: {custom_url}\")\n",
    "print(f\"   API Key: {'*' * (len(custom_key)-4) + custom_key[-4:]}\")\n",
    "\n",
    "print(f\"\\nüìÅ Collection: {COLLECTION_NAME}\")\n",
    "print(f\"üéØ Vector size: {VECTOR_SIZE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèóÔ∏è Dataset Creation\n",
    "\n",
    "Let's create a small, portable dataset of FAQ and documentation entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample dataset\n",
    "df = create_sample_dataset(size=150, seed=42)\n",
    "\n",
    "print(f\"üìä Created dataset with {len(df)} entries\")\n",
    "print(f\"\\nüìÇ Categories: {df['category'].value_counts().to_dict()}\")\n",
    "print(f\"üåç Languages: {df['lang'].value_counts().to_dict()}\")\n",
    "\n",
    "# Preview the data\n",
    "print(\"\\nüîç Sample entries:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üé≤ Generate Embedding Vectors\n",
    "\n",
    "For this fundamentals notebook, we'll use random normalized vectors to focus on Qdrant concepts. In real applications, you'd use actual embedding models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random normalized vectors for demonstration\n",
    "# In production, you would use real embeddings from models like:\n",
    "# - sentence-transformers\n",
    "# - OpenAI embeddings\n",
    "# - FastEmbed\n",
    "\n",
    "np.random.seed(42)\n",
    "vectors = np.random.randn(len(df), VECTOR_SIZE)\n",
    "# Normalize vectors for cosine similarity\n",
    "vectors = vectors / np.linalg.norm(vectors, axis=1, keepdims=True)\n",
    "\n",
    "print(f\"‚úÖ Generated {vectors.shape[0]} vectors of dimension {vectors.shape[1]}\")\n",
    "print(f\"üìè Vector norm check (should be ~1.0): {np.linalg.norm(vectors[0]):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîå Connect to Qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Qdrant Cloud client (requires your own credentials)\n",
    "try:\n",
    "    qdrant_url = os.getenv(\"QDRANT_URL\")\n",
    "    qdrant_key = os.getenv(\"QDRANT_API_KEY\")\n",
    "    if not qdrant_url or not qdrant_key:\n",
    "        raise RuntimeError(\n",
    "            \"QDRANT_URL and QDRANT_API_KEY must be set. Create a free cluster at https://cloud.qdrant.io, \"\n",
    "            \"then set the environment variables as shown above.\"\n",
    "        )\n",
    "\n",
    "    client = QdrantClient(url=qdrant_url, api_key=qdrant_key)\n",
    "    # Test connection\n",
    "    health = client.get_collections()\n",
    "    print(\"üåê Connected to Qdrant Cloud successfully!\")\n",
    "    print(f\"üì¶ Existing collections: {[c.name for c in health.collections]}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Connection failed: {e}\")\n",
    "    print(\"\\nüîß Troubleshooting:\")\n",
    "    print(\"1. Check your QDRANT_URL (should start with https://)\")\n",
    "    print(\"2. Verify your QDRANT_API_KEY from cloud.qdrant.io\")\n",
    "    print(\"3. Make sure your cluster is running (check Qdrant Cloud dashboard)\")\n",
    "    print(\"4. Try setting variables directly in Python:\")\n",
    "    print('   os.environ[\"QDRANT_URL\"] = \"https://your-cluster.qdrant.io:6333\"')\n",
    "    print('   os.environ[\"QDRANT_API_KEY\"] = \"your-api-key\"')\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìö Create Collection\n",
    "\n",
    "Collections in Qdrant are like tables in databases - they store points (vectors + metadata)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define vector configuration\n",
    "# Using a single named vector \"text\" with cosine distance\n",
    "vector_config = VectorParams(\n",
    "    size=VECTOR_SIZE,\n",
    "    distance=Distance.COSINE  # Good for text embeddings\n",
    ")\n",
    "\n",
    "# Create collection\n",
    "ensure_collection(\n",
    "    client=client,\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    vector_config=vector_config,\n",
    "    force_recreate=False  # Set to True to start fresh\n",
    ")\n",
    "\n",
    "# Get collection info\n",
    "info = client.get_collection(COLLECTION_NAME)\n",
    "print(f\"\\nüìã Collection info:\")\n",
    "print(f\"   Points count: {info.points_count}\")\n",
    "print(f\"   Vector size: {info.config.params.vectors.size}\")\n",
    "print(f\"   Distance: {info.config.params.vectors.distance}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì• Ingest Points\n",
    "\n",
    "Points are the core data unit in Qdrant: ID + Vector + Payload (metadata)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define which DataFrame columns to include as payload\n",
    "payload_columns = [\"text\", \"category\", \"lang\", \"timestamp\"]\n",
    "\n",
    "# Upsert points in batches\n",
    "print(\"üì§ Uploading points...\")\n",
    "upsert_points_batch(\n",
    "    client=client,\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    df=df,\n",
    "    vectors=vectors,\n",
    "    payload_cols=payload_columns,\n",
    "    batch_size=50\n",
    ")\n",
    "\n",
    "# Verify upload\n",
    "info = client.get_collection(COLLECTION_NAME)\n",
    "print(f\"\\n‚úÖ Upload complete! Collection now has {info.points_count} points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üè∑Ô∏è Create Payload Indexes\n",
    "\n",
    "Payload indexes speed up filtering operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create indexes for fields we'll filter on\n",
    "create_payload_index(client, COLLECTION_NAME, \"category\", \"keyword\")\n",
    "create_payload_index(client, COLLECTION_NAME, \"lang\", \"keyword\")\n",
    "create_payload_index(client, COLLECTION_NAME, \"timestamp\", \"integer\")\n",
    "\n",
    "print(\"\\nüìñ Payload indexes created for faster filtering!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç First Vector Search\n",
    "\n",
    "Let's perform our first similarity search using one of our vectors as the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the first document's vector as our query\n",
    "query_idx = 0\n",
    "query_vector = vectors[query_idx]\n",
    "query_text = df.iloc[query_idx][\"text\"]\n",
    "\n",
    "print(f\"üîç Query text: '{query_text}'\")\n",
    "print(f\"üìÇ Query category: {df.iloc[query_idx]['category']}\")\n",
    "\n",
    "# Perform search\n",
    "results = search_dense(\n",
    "    client=client,\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    query_vector=query_vector,\n",
    "    limit=5,\n",
    "    with_payload=True\n",
    ")\n",
    "\n",
    "print_search_results(results, \"üéØ Most Similar Documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéõÔ∏è Filtered Search\n",
    "\n",
    "Now let's add filters to search within specific categories or time ranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a filter for product and policy categories\n",
    "category_filter = Filter(\n",
    "    must=[\n",
    "        FieldCondition(\n",
    "            key=\"category\",\n",
    "            match=MatchValue(value=\"product\")\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Search with filter\n",
    "filtered_results = search_dense(\n",
    "    client=client,\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    query_vector=query_vector,\n",
    "    limit=5,\n",
    "    filter_condition=category_filter,\n",
    "    with_payload=True\n",
    ")\n",
    "\n",
    "print_search_results(filtered_results, \"üéØ Product Category Results\")\n",
    "\n",
    "# Compare result counts\n",
    "print(f\"\\nüìä Results comparison:\")\n",
    "print(f\"   Unfiltered: {len(results)} results\")\n",
    "print(f\"   Product only: {len(filtered_results)} results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚è∞ Time-based Filtering\n",
    "\n",
    "Let's filter by timestamp to find recent documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Calculate timestamp for \"last 6 months\"\n",
    "six_months_ago = int(time.time()) - (6 * 30 * 24 * 60 * 60)\n",
    "\n",
    "# Create time-based filter\n",
    "time_filter = Filter(\n",
    "    must=[\n",
    "        FieldCondition(\n",
    "            key=\"timestamp\",\n",
    "            range={\"gt\": six_months_ago}\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Search recent documents\n",
    "recent_results = search_dense(\n",
    "    client=client,\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    query_vector=query_vector,\n",
    "    limit=5,\n",
    "    filter_condition=time_filter,\n",
    "    with_payload=True\n",
    ")\n",
    "\n",
    "print_search_results(recent_results, \"üïí Recent Documents (Last 6 months)\")\n",
    "\n",
    "print(f\"\\nüìä Time filtering:\")\n",
    "print(f\"   All documents: {len(results)} results\")\n",
    "print(f\"   Recent only: {len(recent_results)} results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéöÔ∏è Score Threshold\n",
    "\n",
    "Use score thresholds to filter out low-quality matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search with score threshold\n",
    "high_quality_results = search_dense(\n",
    "    client=client,\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    query_vector=query_vector,\n",
    "    limit=10,\n",
    "    score_threshold=0.3,  # Only results with score >= 0.3\n",
    "    with_payload=True\n",
    ")\n",
    "\n",
    "print_search_results(high_quality_results, \"üéØ High Quality Matches (score >= 0.3)\")\n",
    "\n",
    "print(f\"\\nüìä Quality filtering:\")\n",
    "print(f\"   All results: {len(results)} results\")\n",
    "print(f\"   High quality: {len(high_quality_results)} results\")\n",
    "\n",
    "# Show score distribution\n",
    "scores = [r.score for r in results]\n",
    "print(f\"\\nüìà Score statistics:\")\n",
    "print(f\"   Max: {max(scores):.4f}\")\n",
    "print(f\"   Min: {min(scores):.4f}\")\n",
    "print(f\"   Mean: {np.mean(scores):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üåê Multi-Language Search\n",
    "\n",
    "Filter by language to search within specific locales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search within English documents only\n",
    "english_filter = Filter(\n",
    "    must=[\n",
    "        FieldCondition(\n",
    "            key=\"lang\",\n",
    "            match=MatchValue(value=\"en\")\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "english_results = search_dense(\n",
    "    client=client,\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    query_vector=query_vector,\n",
    "    limit=5,\n",
    "    filter_condition=english_filter,\n",
    "    with_payload=True\n",
    ")\n",
    "\n",
    "print_search_results(english_results, \"üá∫üá∏ English Documents Only\")\n",
    "\n",
    "# Language distribution in results\n",
    "all_langs = [r.payload[\"lang\"] for r in results]\n",
    "en_langs = [r.payload[\"lang\"] for r in english_results]\n",
    "\n",
    "print(f\"\\nüåç Language distribution:\")\n",
    "print(f\"   All results: {pd.Series(all_langs).value_counts().to_dict()}\")\n",
    "print(f\"   English only: {pd.Series(en_langs).value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Complex Filtering\n",
    "\n",
    "Combine multiple filters using boolean logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complex filter: (product OR policy) AND english AND recent\n",
    "complex_filter = Filter(\n",
    "    must=[\n",
    "        # Language must be English\n",
    "        FieldCondition(\n",
    "            key=\"lang\",\n",
    "            match=MatchValue(value=\"en\")\n",
    "        ),\n",
    "        # Timestamp must be recent\n",
    "        FieldCondition(\n",
    "            key=\"timestamp\",\n",
    "            range={\"gt\": six_months_ago}\n",
    "        )\n",
    "    ],\n",
    "    should=[\n",
    "        # Category should be product OR policy\n",
    "        FieldCondition(\n",
    "            key=\"category\",\n",
    "            match=MatchValue(value=\"product\")\n",
    "        ),\n",
    "        FieldCondition(\n",
    "            key=\"category\",\n",
    "            match=MatchValue(value=\"policy\")\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "complex_results = search_dense(\n",
    "    client=client,\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    query_vector=query_vector,\n",
    "    limit=5,\n",
    "    filter_condition=complex_filter,\n",
    "    with_payload=True\n",
    ")\n",
    "\n",
    "print_search_results(complex_results, \"üéØ Complex Filter: Recent English Product/Policy Docs\")\n",
    "\n",
    "if complex_results:\n",
    "    categories = [r.payload[\"category\"] for r in complex_results]\n",
    "    languages = [r.payload[\"lang\"] for r in complex_results]\n",
    "    \n",
    "    print(f\"\\n‚úÖ Filter verification:\")\n",
    "    print(f\"   Categories found: {set(categories)}\")\n",
    "    print(f\"   Languages found: {set(languages)}\")\n",
    "    print(f\"   All recent: {all(r.payload['timestamp'] > six_months_ago for r in complex_results)}\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  No results found matching the complex filter criteria\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üñ•Ô∏è Web UI Checkpoint (Optional)\n",
    "\n",
    "If you're running Qdrant locally, you can explore the collection in the web UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Qdrant Cloud Dashboard Access\n",
    "qdrant_url = os.getenv(\"QDRANT_URL\", \"\")\n",
    "\n",
    "if \"localhost\" in qdrant_url:\n",
    "    print(\"üåê Local Qdrant Web UI:\")\n",
    "    print(f\"   Open: {qdrant_url.replace(':6333', ':6333/dashboard')}\")\n",
    "    print(f\"   Navigate to collection: {COLLECTION_NAME}\")\n",
    "else:\n",
    "    print(\"üåê Qdrant Cloud Dashboard:\")\n",
    "    print(\"   1. Go to https://cloud.qdrant.io\")\n",
    "    print(\"   2. Select your cluster\")\n",
    "    print(\"   3. Use the 'Console' tab to:\")\n",
    "    print(\"      ‚Ä¢ View collection schema and points\")\n",
    "    print(\"      ‚Ä¢ Run vector searches\")\n",
    "    print(\"      ‚Ä¢ Test payload filters\")\n",
    "    print(\"      ‚Ä¢ Monitor cluster performance\")\n",
    "    print(f\"   4. Explore collection: {COLLECTION_NAME}\")\n",
    "    \n",
    "print(\"\\nüîç Try these in the dashboard:\")\n",
    "print(\"   ‚Ä¢ Browse points and payload data\")\n",
    "print(\"   ‚Ä¢ Run similarity searches\")\n",
    "print(\"   ‚Ä¢ Test different filters\")\n",
    "print(\"   ‚Ä¢ View collection statistics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Summary & Key Concepts\n",
    "\n",
    "Let's summarize what we've learned about Qdrant fundamentals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collection statistics\n",
    "final_info = client.get_collection(COLLECTION_NAME)\n",
    "\n",
    "print(\"üéâ Qdrant Fundamentals Summary\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"\\nüìö Collection: {COLLECTION_NAME}\")\n",
    "print(f\"   üìä Total points: {final_info.points_count}\")\n",
    "print(f\"   üìè Vector dimension: {final_info.config.params.vectors.size}\")\n",
    "print(f\"   üìê Distance metric: {final_info.config.params.vectors.distance}\")\n",
    "\n",
    "print(f\"\\nüè∑Ô∏è Payload structure:\")\n",
    "sample_point = client.retrieve(COLLECTION_NAME, ids=[1])[0]\n",
    "for key, value in sample_point.payload.items():\n",
    "    print(f\"   {key}: {type(value).__name__} - {value}\")\n",
    "\n",
    "print(f\"\\nüîç Search capabilities demonstrated:\")\n",
    "print(\"   ‚úÖ Basic vector similarity search\")\n",
    "print(\"   ‚úÖ Payload filtering (category, language, time)\")\n",
    "print(\"   ‚úÖ Complex boolean filters (AND, OR logic)\")\n",
    "print(\"   ‚úÖ Score thresholding\")\n",
    "print(\"   ‚úÖ Payload indexes for fast filtering\")\n",
    "\n",
    "print(f\"\\nüéØ Key takeaways:\")\n",
    "print(\"   ‚Ä¢ Collections store points (vectors + metadata)\")\n",
    "print(\"   ‚Ä¢ Payload enables rich filtering capabilities\")\n",
    "print(\"   ‚Ä¢ Indexes dramatically speed up filtered searches\")\n",
    "print(\"   ‚Ä¢ Cosine distance works well for text embeddings\")\n",
    "print(\"   ‚Ä¢ Score thresholds help filter low-quality matches\")\n",
    "\n",
    "print(f\"\\nüöÄ Ready for Notebook 2: Hybrid Search!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéÆ Stretch Goals (Optional)\n",
    "\n",
    "Try these additional experiments to deepen your understanding:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîç Full-Text Search with Payload Index\n",
    "\n",
    "Add a full-text index to search within document text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create full-text index on the text field\n",
    "try:\n",
    "    create_payload_index(client, COLLECTION_NAME, \"text\", \"text\")\n",
    "    print(\"‚úÖ Full-text index created!\")\n",
    "    \n",
    "    # Example: Search for documents containing specific terms\n",
    "    # Note: This searches in payload, not vector similarity\n",
    "    text_filter = Filter(\n",
    "        must=[\n",
    "            FieldCondition(\n",
    "                key=\"text\",\n",
    "                match={\"text\": \"password\"}  # Find docs mentioning \"password\"\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    text_results = client.scroll(\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        scroll_filter=text_filter,\n",
    "        limit=5,\n",
    "        with_payload=True\n",
    "    )[0]  # scroll returns (points, next_page_offset)\n",
    "    \n",
    "    print(f\"\\nüîç Full-text search results for 'password':\")\n",
    "    for i, point in enumerate(text_results, 1):\n",
    "        print(f\"{i}. {point.payload['text'][:80]}...\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Note: Full-text search might not be available: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéØ Second Named Vector Slot\n",
    "\n",
    "Prepare for multi-vector scenarios by adding a second vector configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This would typically be done when creating the collection\n",
    "# For demonstration, let's create a new collection with multiple named vectors\n",
    "\n",
    "MULTI_VECTOR_COLLECTION = \"workshop_multi_vector\"\n",
    "\n",
    "# Define multiple named vectors\n",
    "multi_vector_config = {\n",
    "    \"text_dense\": VectorParams(size=384, distance=Distance.COSINE),\n",
    "    \"text_sparse\": VectorParams(size=0, distance=Distance.DOT)  # Sparse placeholder\n",
    "}\n",
    "\n",
    "try:\n",
    "    ensure_collection(\n",
    "        client=client,\n",
    "        collection_name=MULTI_VECTOR_COLLECTION,\n",
    "        vector_config=multi_vector_config,\n",
    "        force_recreate=True\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ Created multi-vector collection: {MULTI_VECTOR_COLLECTION}\")\n",
    "    \n",
    "    # Show collection info\n",
    "    info = client.get_collection(MULTI_VECTOR_COLLECTION)\n",
    "    print(f\"   Vector configurations:\")\n",
    "    if hasattr(info.config.params, 'vectors') and isinstance(info.config.params.vectors, dict):\n",
    "        for name, config in info.config.params.vectors.items():\n",
    "            print(f\"     {name}: size={config.size}, distance={config.distance}\")\n",
    "    \n",
    "    print(f\"\\nüöÄ Ready for hybrid search in Notebook 2!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Note: Multi-vector setup encountered an issue: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üßπ Cleanup (Optional)\n",
    "\n",
    "Uncomment to clean up collections after the workshop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to clean up collections\n",
    "# PRESERVE_COLLECTIONS = True  # Set to False to delete collections\n",
    "\n",
    "# if not PRESERVE_COLLECTIONS:\n",
    "#     try:\n",
    "#         client.delete_collection(COLLECTION_NAME)\n",
    "#         print(f\"üóëÔ∏è Deleted collection: {COLLECTION_NAME}\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"Note: Could not delete collection: {e}\")\n",
    "        \n",
    "#     try:\n",
    "#         client.delete_collection(MULTI_VECTOR_COLLECTION)\n",
    "#         print(f\"üóëÔ∏è Deleted collection: {MULTI_VECTOR_COLLECTION}\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"Note: Could not delete collection: {e}\")\n",
    "# else:\n",
    "#     print(f\"üíæ Collections preserved for next notebooks\")\n",
    "\n",
    "print(f\"\\n‚ú® Notebook 1 complete! Move on to 02_hybrid_search.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
